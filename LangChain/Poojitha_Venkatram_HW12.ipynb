{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment-12\n",
        "### Poojitha Venkatram\n",
        "### Github Link- https://github.com/poojithavenkatram/Deep-Learning"
      ],
      "metadata": {
        "id": "mQh_dsJitooK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part A: Build a code understanding model. Upload your own custom code files to the model and ask questions based on the code file as context."
      ],
      "metadata": {
        "id": "xE_eXY0YQt0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEv13cJPgqM9",
        "outputId": "893610fc-47b5-41c3-c698-b4d2b76e6307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG"
      ],
      "metadata": {
        "id": "8M_h0PcVgbgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the needed packages"
      ],
      "metadata": {
        "id": "HoAq3UmUgjCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "!pip install langchain_experimental\n",
        "!pip install \"langchain[docarray]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcPQDqbbCF7y",
        "outputId": "357871ee-fc97-4f01-a085-33be857c7399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/867.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/867.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m604.2/867.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/867.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.48->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.50 langchain-text-splitters-0.0.1 langsmith-0.1.54 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.25.2-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.2\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.57-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain<0.2.0,>=0.1.15 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.1.17)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.41 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.1.50)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.0.36)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (8.2.3)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.41->langchain_experimental) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.0.0)\n",
            "Installing collected packages: langchain_experimental\n",
            "Successfully installed langchain_experimental-0.0.57\n",
            "Requirement already satisfied: langchain[docarray] in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.1.50)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (8.2.3)\n",
            "Collecting docarray[hnswlib]<0.33.0,>=0.32.0 (from langchain[docarray])\n",
            "  Downloading docarray-0.32.1-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain[docarray]) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain[docarray]) (0.9.0)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.10.3)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (13.7.1)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Collecting hnswlib>=0.6.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.20.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain[docarray]) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain[docarray]) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain[docarray]) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (0.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2319656 sha256=ea75ee06de715aecb81cdd0b5e5578df8e28f8365a018cf4aa28c4ce54240594\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: types-requests, hnswlib, docarray\n",
            "Successfully installed docarray-0.32.1 hnswlib-0.8.0 types-requests-2.31.0.20240406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "VmKu8KtYGrey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup OPEN AI Key"
      ],
      "metadata": {
        "id": "LI_aqBFKIOaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Actual API key\n",
        "api_key = ''\n",
        "\n",
        "# Set your API key\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Check that the environment variable was set correctly\n",
        "print(\"OPENAI_API_KEY has been set!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF5Xj6anHqot",
        "outputId": "ef90b96e-1f79-42ce-a134-b63395cb85f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY has been set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-4-turbo\""
      ],
      "metadata": {
        "id": "_jYVCsSpIZhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "gp7ESc2NKASJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeaoOBNvOVDZ",
        "outputId": "096c3810-2b85-438b-8070-357fb87559a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from PyPDF2 import PdfReader\n",
        "import os"
      ],
      "metadata": {
        "id": "Xs0hDDHJOSvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting text from PDF"
      ],
      "metadata": {
        "id": "NlKuCAL7Oe7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Extract text from a specified PDF file path\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/Sample.pdf\"\n",
        "data = extract_text_from_pdf(pdf_path)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR7WK_CcKBC2",
        "outputId": "1ab822d3-d2f3-4c56-cb9b-1d6787657116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response Prediction of Structural System Subject to  Earthquake \n",
            "Motions using Artificial Neural Network \n",
            " \n",
            "S. Chakraverty*,  T. Marwala** , Pallavi Gupta* and  Thando Tettey**  \n",
            " \n",
            "*B.P.P.P. Division, Central Building Research Institu te \n",
            "Roorkee-247 667, Uttaranchal, India \n",
            "e-mail :sne_chak@yahoo.com \n",
            " \n",
            "** School of Electrical and Information Engineering, \n",
            "University of the Witwatersrand, Private Bag 3 \n",
            "Wits, 2050,Republic of South Africa  \n",
            "  \n",
            "Abstract \n",
            "This paper uses Artificial Neural Network (ANN) models to compute response of \n",
            "structural system subject to Indian earthquakes at Chamoli and Uttarkashi \n",
            "ground motion data. The system is first trained for a si ngle real earthquake data. \n",
            "The trained ANN architecture is then used to simulate e arthquakes with various \n",
            "intensities and it was found that the predicted responses given by ANN model \n",
            "are accurate for practical purposes. When the ANN is trai ned by a part of the \n",
            "ground motion data, it can also identify the responses of the structural system \n",
            "well. In this way the safeness of the structural systems ma y be predicted in case \n",
            "of future earthquakes without waiting for the earthq uake to occur for the lessons. \n",
            "Time period and the corresponding maximum response of t he building for an \n",
            "earthquake has been evaluated, which is again trained to predict the maximum \n",
            "response of the building at different time periods. T he trained time period versus \n",
            "maximum response ANN model is also tested for real earth quake data of other \n",
            "place, which was not used in the training and was found to be in good \n",
            "agreement.  \n",
            " \n",
            "Keywords : Earthquake, Neural Network, Frequency, Structure, Buil ding. \n",
            "  \n",
            " \n",
            " \n",
            "1 Introduction \n",
            " \n",
            "Real earthquake ground motion at a particular build ing site is very complicated. \n",
            "The response of a building to an earthquake is dynamic and for a dynamic \n",
            "response, the building is subjected to a vibratory shakin g of the base. Exactly \n",
            "how a building responds is complex and depends on the am plitude and \n",
            "frequency of vibration along with the material and d esign of the building. All \n",
            "buildings have a \"natural frequency\" associated with the m. If strain is placed on \n",
            "to the structure and then let it snap back into equilibr ium, it will sway back and \n",
            "forth with an amplitude that decays with time. If the  ground shakes with the same \n",
            "frequency as a building's natural frequency, it will cau se the amplitude of sway to \n",
            "get larger and larger such that, the ground shaking is i n resonance with the \n",
            "building's natural frequency. This produces the most stra in on the components of \n",
            "the building and can quickly cause the building to colla pse. Powerful technique of \n",
            "Artificial Neural Network (ANN) has been used to model the problem for one \n",
            "storey structure. Among the different types of ANN, the  feedforward, multilayer, \n",
            "supervised neural network with error back propagation al gorithm, the BPN [1] is \n",
            "the most frequently applied NN model. Dynamic response of a structure to strong \n",
            "earthquake ground motion may be investigated by diff erent methods. The \n",
            "method, that has been used here, is to create a trained  black box containing the \n",
            "characteristics of the structure and of the earthquake moti on which can predict \n",
            "the dynamic response for any other earthquake for a pa rticular structure.  \n",
            " \n",
            "Artificial Neural Network (ANN) have gradually been es tablished as a powerful \n",
            "soft computing tool in various fields because of their excellent learning capacity \n",
            "and their high tolerance to partially inaccurate data.  ANN has, recently been \n",
            "applied to assess damage in structures. Stefano et al.[3]  used probabilistic \n",
            "Neural Networks for seismic damage prediction. Many meth ods viz. [4]-[9] were \n",
            "introduced for response estimation and for structural con trol. Zhao et al.[10] applied a counter-propagation NN to locate damage in beams and frames. \n",
            "KuZniar and Waszczyszyn [11] simulated the dynamic response for prefabricated \n",
            "building using ANN. Elkordy et al.[12] used a back-propa gation neural network \n",
            "with modal shapes in the input layer  to detect the sim ulated damage of \n",
            "structures. Muhammad [13] gives certain ANN applications in concrete \n",
            "structures. Pandey and Barai [14] detected damage in a bridge truss by applying \n",
            "ANN of multilayer perceptron architectures to numericall y simulated data. Some \n",
            "studies such as [15]-[17] used artificial neural network f or structural damage \n",
            "detection and system identification.  \n",
            " \n",
            "In the present paper, the Chamoli earthquake ground acceleration at Barkot (NE) \n",
            "and Uttarkashi earthquake ground acceleration recorded a t Barkot (NE and NW)  \n",
            "have been considered based on the authors' previous stud y [18]. From their \n",
            "ground acceleration the responses are computed using the u sual procedure. \n",
            "Then the ground acceleration and the corresponding re sponse are trained using \n",
            "Artificial Neural Network (ANN) with and without damp ing. After training the \n",
            "network with one earthquake, the converged weight mat rices are stored. In order \n",
            "to show the power of these converged (trained) networ ks other earthquakes are \n",
            "used as input to predict the direct response of the structu re without using any \n",
            "mathematical analysis of the response prediction. Simi larly, the various time \n",
            "periods of one earthquake and its corresponding maximu m responses are \n",
            "trained. Then the converged weights are used to predict  the maximum response \n",
            "directly to the corresponding time period. Various othe r results related to use of \n",
            "these trained networks are discussed for future / other e arthquakes. \n",
            " \n",
            "2 Artificial Neural Network  \n",
            " \n",
            "Artificial neural systems are present day machines that ha ve great potential to \n",
            "improve the quality of our life. Advances have been made in applying such \n",
            "systems for problems found difficult for traditional co mputation. A neural network \n",
            "is a parallel, distributed information processing structur e consists of processing \n",
            "elements called neurons, which are interconnected and u nidirectional signal channels called connections. The general structure of the network that have \n",
            "been used here is given in Fig.1. the structure consists of  three layers : the input \n",
            "layer, the hidden layer and the output layer. The i nput layer is made up of one or \n",
            "more neurons or processing elements that collectively re present the information \n",
            "in a particular pattern of a training set. The hidden  layer also consists of one or \n",
            "more neurons. Its purpose is simply to transform the info rmation from the input \n",
            "layer to prepare it for the output layer. The outpu t layer, which has one or more \n",
            "neurons, uses input from the hidden layer (which is a tr ansformation of the input \n",
            "layer) to produce an output value for the entire ne twork. The output is used to \n",
            "interpret the training and classification results of the  network. The processing \n",
            "elements or neurons are connected to each other by adju stable weights. The \n",
            "input/output behaviour of the network changes if the w eights are changed. So, \n",
            "the weights of the net may be chosen in such a way so as to achieve a desired \n",
            "output. To satisfy this goal, systematic ways of adjustin g the weights have to be \n",
            "developed, which are known as training or learning al gorithm.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " Output Units \n",
            "Hidden units \n",
            "Input Units  Z1 Zj Pj \n",
            "P1 O1 Ok  \n",
            " \n",
            "Fig.1. Layered Feedforward Neural Network \n",
            " \n",
            "3 Error Back Propagation Training Algorithm (EBPTA)   \n",
            " \n",
            "Here, Error Back Propagation Training algorithm and f eedforward recall with one \n",
            "hidden layer has been used. In Fig. 1, Z i, P j and O k are input, hidden and output \n",
            "layer respectively. The weights between input and hidd en layers are denoted by \n",
            "νji  and the weights between hidden and output layers are  denoted by W kj . The \n",
            "procedure may easily be written down for the processing of this algorithm. \n",
            " \n",
            "Given R training pairs  \n",
            "where Z i (Ix1) are input and d i (Kx1) are desired values for the given inputs, the \n",
            "error value is computed as \n",
            "for the present neural network as shown in Fig. 1.  \n",
            " \n",
            "The error signal terms of the output ( δOk ) and hidden layers ( δPj ) are written \n",
            "respectively as, \n",
            "Consequently, output layer weights (W kj ) and hidden layer weights ( δji ) are \n",
            "adjusted as, \n",
            " \n",
            "Where, β is the learning constant. \n",
            " { }RRdZ dZdZ , ;......... ,;, 2211\n",
            "( ) K k O d E k k ,..... 2 , 1 ,21 2= − =\n",
            "K k O O d k k k Ok ,........ 2 , 1 ), 1)( ( *5 . 02= − − = δ\n",
            "∑ = − =\n",
            "=K\n",
            "kPj Ok j Pj J j W P\n",
            "12,.... 2 , 1 , ) 1 ( *5 . 0 δ δ\n",
            "J,..... 2 , 1j and K..... 2 , 1 k,P W Wj Ok )Old (\n",
            "kj ) New (\n",
            "kj = = + = βδ I ,....... 2 , 1 iand J....... 2 , 1j ,Zi Pj )Old (\n",
            "ji ) New (\n",
            "ji = = + = βδ ν ν \n",
            " \n",
            " \n",
            "4 Response Prediction \n",
            " \n",
            "The basic idea behind the proposed methodology is to pr edict the structural \n",
            "response of single degree of freedom system i.e. single storey building subject to \n",
            "various earthquake forces. Two cases viz without damping and with damping \n",
            "have been considered for the analysis. \n",
            " \n",
            "Case(i)  : Without damping \n",
            " \n",
            "Let M be the mass of the generalized one storey structur e, K the stiffness of the \n",
            "structure and x be the displacement relative to the gro und then the equation of \n",
            "motion may be written as: \n",
            " \n",
            "where, \n",
            " \n",
            "Equation (1) may be written as, \n",
            " \n",
            "Where  ω2=K/M, is the natural frequency parameter of the undam ped structure. \n",
            " \n",
            "The solution of equation (2) [Ref. 2] is given by \n",
            "From this solution the response of the structure viz. acceleration is obtained for \n",
            "no damping. \n",
            " on. accelerati Ground ant, Displaceme xon, accelerati Response x\n",
            "===\n",
            "& &&&) 1 ( aM Kx xM & & & & −= +\n",
            ") 2 (2a x x & & & & −= +ω\n",
            "∫ − −=t\n",
            "0) 3 ( d)] t ( sin[ )( a1) t ( x ττ ω τω& & \n",
            " \n",
            " \n",
            "Case (ii) : With damping  \n",
            " \n",
            "Let M be the mass of the generalized one storey structur e, K the stiffness of the \n",
            "structure, C the damping and x be the displacement rela tive to the ground then \n",
            "the equation of motion may be written as: \n",
            " \n",
            "where \n",
            " \n",
            "Equation (4) may be written as, \n",
            " \n",
            "Where ξω = C/2M and ω2=K/M, is the natural frequency parameter of the \n",
            "undamped structure. \n",
            "The solution of equation (5) [Ref.2] is given by \n",
            " \n",
            "From this solution the response of the structure viz. acceleration is obtained for \n",
            "damping. \n",
            "  \n",
            "Now, the neural network architecture is constructed, takin g ground acceleration \n",
            "as input and the response obtained from the above solu tion is taken as output for \n",
            "each time step. Therefore, the whole network consists of o ne input layer, one \n",
            "hidden layer with varying nodes and one output layer  as shown in Fig.1. Similarly ) 4 ( aM Kx xCxM & & && & −= + +\n",
            "on. accelerati Ground ant, Displaceme xvelocity, Response xon, accelerati Response x\n",
            "====\n",
            "& &&& &\n",
            ") 5 ( 22a x x x & & && & −= + + ω ωξ\n",
            "∫ − − − −=t\n",
            "0) 6 ( d)] t ( sin[ )] t ( [exp )( a1) t ( x ττ ω τ ωξ τω& &for the other problem of time period vs. maximum resp onse the input and output \n",
            "layer contain the time period and the corresponding ma ximum response \n",
            "respectively at each interval for the particular structur e. \n",
            " \n",
            "5 Numerical Results and Discussions \n",
            " \n",
            "For the present study two Indian earthquakes viz. the Chamoli Earthquake (max. \n",
            "ground acceleration =0.16885 m/sec/sec) at Barkot in NE (north–east) direction \n",
            "shown in Fig.2(a) and the Uttarkashi earthquake  (maxi mum ground acceleration \n",
            "= 0.931 m/sec/sec) at Barkot in NE (north–east) and NW ( north-west) direction \n",
            "as given in Figs. 2(b) and 2(c) have been considered for  training and testing. \n",
            " \n",
            "Initially, the system without damping is studied and fo r that the ground \n",
            "acceleration of Chamoli earthquake at Barkot (NE) was use d to compute the \n",
            "response for single storey structure using usual procedure  from Eq.(3). The \n",
            "obtained response and the ground acceleration is traine d first for the assumed \n",
            "frequency parameters ω=0.5 and ω=0.01 for time range 0 to 14.92 sec.(748 data \n",
            "points) for the mentioned earthquake. Simulations have  been done for different \n",
            "hidden layer nodes and it was seen that the response re sult is almost same and \n",
            "good for 5 to 20 nodes in the hidden layer. However,  10 hidden layer nodes are \n",
            "used here to generate further results. \n",
            " \n",
            "After training ground acceleration and response data fo r Chamoli earthquake at \n",
            "Barkot (NE) for 10 nodes in hidden layer, the weights are stored and they are \n",
            "used to predict responses for various intensity earthquakes.  The plot in Fig. 3(a) \n",
            "shows response comparison between neural and desired for t he 80% of Chamoli \n",
            "earthquake at Barkot (NE) for ω=0.01(maximum response=0.135079m/sec/sec). \n",
            "Similarly, the response comparison for 120% Chamoli ear thquake at Barkot (NE) \n",
            "for ω=0.5 (Maximum response=0.20260 m/sec/sec) is shown in Fig 3(b). \n",
            " \n",
            "Next, a part of the ground acceleration is used for the  training and it will be \n",
            "shown that the present ANN can predict the whole perio d of the response using \n",
            "the trained ANN by the part of the data.  So, the g round acceleration and response data with Chamoli earthquake is trained for an example with the time \n",
            "range 0 to 10.96 sec.(550 data points). Its weights are stored to find the \n",
            "response for the time range 0 to 14.92 sec. (whole per iod) at different \n",
            "percentages of the earthquake in order to test the net work learning for the points \n",
            "outside the training set. Figs. 4(a) and 4(b) show the response comparison \n",
            "between neural and desired for ω=0.01, (maximum response=0.168849 \n",
            "m/sec/sec) and for ω=0.5 (maximum response=0.168841 m/sec/sec) at the time \n",
            "range 0 to 10.96 sec. The response comparison between neural and desired for \n",
            "ω=0.01 with 120% of the earthquake force (maximum respo nse = 0.20260 \n",
            "m/sec/sec) from the time range 0 to 14.92 sec.(748 data  points) is incorporated \n",
            "in Fig. 5(a). It is obtained from the weights of the  trained data for the time range 0 \n",
            "to 10.96 sec. (550 data points). From the same weights,  neural responses for \n",
            "80% of earthquake force, is computed with ω=0.5(maximum response=0.135073 \n",
            "m/sec/sec), for the time range 0 to 14.92 sec. (748 dat a points) and it is plotted in \n",
            "Fig. 5(b).  \n",
            " \n",
            "The system with damping is then considered and for this,  first from the ground \n",
            "acceleration of Chamoli Earthquake at Barkot (NE), the response is computed \n",
            "using Eq.(6). The obtained responses and the ground acc eleration are trained by \n",
            "the said ANN model for an example structural system wit h frequency parameter \n",
            "ω= 0.68981 and damping = 1.58033. This training was do ne for the total time \n",
            "range 0 to 14.92 sec. (748 points, earthquake period).  Plot of 100% response \n",
            "comparison between neural and desired for Chamoli Eart hquake at barkot (NE) \n",
            "is shown in Fig. 6(a). After training ground accelerati on and response data for \n",
            "Chamoli Earthquake for various nodes in the hidden l ayer it was confirmed that \n",
            "10 nodes are again sufficient for the prediction. So, the weights corresponding to \n",
            "10 hidden nodes are stored and they are used to predict  responses for various \n",
            "intensity earthquakes. The response for 50% ( ω= 0.68981, damping = 1.58033 \n",
            "and maximum response = 0.00375 m/sec/sec) of the Chamol i Earthquake at \n",
            "Barkot (NE) and its comparison with the desired response are shown in Fig. 6(b). \n",
            "Similarly, the response comparison between neural and desired is shown in Fig. 6(c) ( ω= 0.68981, damping = 1.58033 and maximum response fo r 120% = \n",
            "0.00910 m/sec/sec) for 120% of earthquake acceleration. \n",
            " \n",
            "Finally, the Uttarkashi earthquake at Barkot (NW) gro und acceleration is used \n",
            "with damping = 0.05, at different time periods ( t =  1/omega) ranging from 0.5 to \n",
            "10 with an interval of 0.02 (620 data points) for ev aluating the maximum \n",
            "responses corresponding to each time period using Eq. (6) . The obtained time \n",
            "periods and the corresponding responses are trained and t hen the converged \n",
            "weights are stored. The comparison between neural and d esired results is shown \n",
            "in Fig. 7(a). The stored weights were then used to pre dict the response for \n",
            "different time periods lying in the same range of 0. 5 to 10 but at different time \n",
            "interval of 0.5 for another earthquake such as Uttarkashi  earthquake at Tehri \n",
            "(NW), The results are depicted in  Fig. 7(b) showing go od comparison between \n",
            "ANN model and desired results. \n",
            " \n",
            "6 Conclusions \n",
            " \n",
            "This paper uses the powerful soft computing technique (Ar tificial Neural Network) \n",
            "to compute structural response of single degree of freed om system subject to \n",
            "Indian earthquakes at Chamoli and Uttarkashi ground mo tion data. Also this \n",
            "technique is used to predict the maximum response corresp onding to various \n",
            "time periods. It is shown here that once the training is done then the trained \n",
            "architecture may be used to simulate for various intensit y earthquakes, thereby \n",
            "showing the responses of the system which depend upon the  structural \n",
            "properties (mass and stiffness) of the structure. If the ne twork is trained for \n",
            "various time periods of one earthquake and its correspon ding maximum \n",
            "responses then the model can predict the maximum respons e directly to the \n",
            "corresponding time period for any other earthquake tha t had not been used \n",
            "during the training. In this way the safety of the str uctural systems may be \n",
            "predicted in case of future earthquakes.  \n",
            " \n",
            "Acknowledgements The authors would like to thank Department of Science an d Technology, India for \n",
            "funding and Director C.B.R.I. for giving permission to  publish this paper.  \n",
            " \n",
            "References \n",
            "[1] D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learn ing international \n",
            "representation by error propagation. In Parallel Dist ributed Processing, D.E. \n",
            "Rumelhart, et al. (eds). (The MIT Press: Cambridge, MA , 1986). \n",
            "[2] N.M. Newmark, E. Rosenblueth, Fundamentals of Eart hquake Engineering, \n",
            "(Prentice-Hall, Inc. Englewood Cliffs, N.J, 1971). \n",
            "[3] A. De Stefano, D.Sabia, L.Sabia, Probabilistic Ne ural Networks for Seismic \n",
            "Damage Mechanisms Prediction, Earthquake Engineering an d Structural \n",
            "Dynamics, Vol. 28, No. 8 (1999) 807- \n",
            "[4] A. Kallassy, A new neural Network for Response Estima tion, Computers and \n",
            "Structures, Vol. 81, No. 26-27 (2003), 2417-2429 \n",
            "[5] A. Zhang, L. Zhang, RBF Neural Networks for the P rediction of Building \n",
            "Interference effects, Computers and Structures, Vol. 82, No. 27(2004) 2333 \n",
            "-2339 \n",
            "[6] Brown.S. Aaron, T.Y. Henry, Yang, Neural Networ ks for multi Objective \n",
            "Adaptive Structural Control, Structural Engineering A SCE, Vol.127, No.2, \n",
            "(2001) 203- \n",
            "[7] C.S. Huang, S.L. Hung, C.M. Wen, T.T.Tu, A Neur al Network Approach for \n",
            "Structural Identification and Diagnosis of a Building f rom Seismic Response \n",
            "Data, Earthquake Engineering and Structural Dynamics, Vol. 32, No. 2, \n",
            "(2003) 187-  \n",
            "[8] C.Y. Kao, Shin Lin Hung, Detection of structural Damage via Free Vibration \n",
            "Responses generated by Approximating Artificial Neural  Network, \n",
            "Computers and Structures,Vol.81,No. 28-29 (2003), 2631 -2644 \n",
            "[9] D.A. Liut, E.E Matheu, M.P. Singh, D.T. Mook, Ne ural Network Control of \n",
            "building Structures by a Force Matching Training Scheme,  Earthquake \n",
            "Engineering and Structural Dynamics, Vol. 28, No. 12 (1999) 1601- [10] J .Zhao, J.N. Ivan, J.T. DeWolf, Structural damage  detection using artificial \n",
            "neural networks. Journal of Infrastructure Systems (ASCE)  Vol.4, No.(3) \n",
            "(1998) 93 – 101. \n",
            "[11] Krystyna KuZniar, Zenon Waszczyszyn, Neural Simulat ion of Dynamic \n",
            "Response of Prefabricated Buildings Subjected to Parase ismic Excitations, \n",
            "Computers and Structures,Vol. 81, No. 24-25 (2003) 235 3-2360 \n",
            "[12] M.F. Elkordy, K.C. Chang, G.C. Lee, Neural netw orks trained by analytically \n",
            "simulated damage states. Journal of Computing in Civil Engineering (ASCE) \n",
            "Vol. 7, No.2 (1993) 130 – 145. \n",
            "[13] N.S. Hadi Muhammad, Neural Networks Applications i n Concrete \n",
            "Structures, Computers and Structures, Vol.81, No. 6 (20 03) 373-381 \n",
            "[14] P.C. Pandey, S.V. Barai, Multilayer perceptron in damage detection of \n",
            "bridge structures. Computers and Structures Vol. 54, No.4  (1995) 597- 608. \n",
            "[15] Q. Chen, Y.W. Chan, K. Worden, Structural Fault  Diagnosis and Isolation \n",
            "using Neural Network Based on Response Only Data, Vol . 81, No. 22-23 \n",
            "(2003) 2165 -2172 \n",
            "[16] S.F. Masri, A.W. Smyth, A.G. Chassiakos, T.K. Caug hey, N.F. Hunter, \n",
            "Application of Neural networks for detection of changes i n nonlinear \n",
            "systems. Journal of Engineering Mechanics (ASCE), Vol. 126 , No.70 (2000) \n",
            "666 – 676. \n",
            "[17] S.L. Hung, C.Y. Kao, Structural Damage Detection  Using the Optimal \n",
            "Weights of the Approximating Artificial Neural Networ ks, Earthquake \n",
            "Engineering and Structural Dynamics,Vol. 31, No.2, (2 002) 217-  \n",
            "[18] V.K. Mathur, S. Chakraverty and Pallavi Gupta,  Response Prediction of \n",
            "Typical Rural House Subject to Earthquake Motions Using Artificial Neural \n",
            "Networks. Journal of Indian Building Congress, Vol.11, No.2 (2004) 99-105. \n",
            " \n",
            " \n",
            " \n",
            "     \n",
            "         Fig. 2(a). Chamoli Earthquake at Barkot  in NE dire ction \n",
            "                       Peak Acceleration = 0.16885m /sec/sec  \n",
            "            \n",
            "Fig. 2(b) Uttarkashi Earthquake at Barkot in NE dir ection \n",
            "       Peak Acceleration : 0.9317m/sec/sec  \n",
            "                                \n",
            " Fig. 2(c). Uttarkashi Earthquake at Barkot in NW d irection \n",
            "             Peak Acceleration : 0.8470m/sec/sec  -15 -10 -5 0510 15 20 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration \n",
            "-1 -0.8 -0.6 -0.4 -0.2 00.2 0.4 0.6 0.8 11.2 \n",
            "0 5 10 15 20 25 30 35 \n",
            "Time Acceleration \n",
            "-1 -0.8 -0.6 -0.4 -0.2 00.2 0.4 0.6 0.8 1\n",
            "0 5 10 15 20 25 30 35 \n",
            "Time Acceleration              \n",
            " \n",
            "Fig. 3(a). 80% Response comparison Between Neural a nd Desired of Chamoli \n",
            "                         Earthquake at Barkot (NE) for ωω ωω=0.01  \n",
            " \n",
            "Fig. 3(b). 120% Response comparison Between Neural and Desired of Chamoli \n",
            "                         Earthquake at Barkot (NE) for ωω ωω=0.5  \n",
            " -0.1 -0.05 00.05 0.1 0.15 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired \n",
            "-0.15 -0.1 -0.05 00.05 0.1 0.15 0.2 0.25 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired                 \n",
            "Fig. 4(a). Response Comparison Between Neural and D esired (550 points) \n",
            "                                   of Chamoli Earthquake at Barkot (NE)  for ωω ωω=0.01 \n",
            " \n",
            "Fig. 4(b). Response Comparison Between Neural and D esired (550 points) \n",
            "                            of Chamoli Earthquake at Barkot (NE)  for ωω ωω=0.5 \n",
            " \n",
            " -0.15 -0.1 -0.05 00.05 0.1 0.15 0.2 \n",
            "0 2 4 6 8 10 12 \n",
            "Time Acceleration Neural Desired \n",
            "-0.15 -0.1 -0.05 00.05 0.1 0.15 0.2 \n",
            "0 2 4 6 8 10 12 \n",
            "Time Acceleration Neural Desired                 \n",
            "Fig. 5(a). 120% Response Comparison Between Neural and Desired \n",
            "                of Chamoli Earthquake at Barkot (NE )  (748 points)   ωω ωω=0.01 \n",
            "(After training from 550 points) \n",
            " \n",
            "Fig. 5(b). 80% Response Comparison Between Neural a nd Desired \n",
            "                                  of Chamoli Earthquake at Barkot (NE)  (748 points)   ωω ωω=0.5  \n",
            "      (After training from 550 points) -0.15 -0.1 -0.05 00.05 0.1 0.15 0.2 0.25 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired \n",
            "-0.1 -0.05 00.05 0.1 0.15 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired Fig.6(a). 100% Response Comparison Between Neural a nd Desired of Chamoli \n",
            "                          Earthquake at Barkot (NE) with Damping \n",
            "Fig.6(b). 50% Response Comparison Between Neural an d Desired of Chamoli \n",
            "                          Earthquake at Barkot (NE)  with Damping  \n",
            "Fig.6(c). 120% Response Comparison Between Neural a nd Desired of Chamoli \n",
            "                          Earthquake at Barkot (NE)  with Damping  -0.006 -0.004 -0.002 00.002 0.004 0.006 0.008 0.01 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired \n",
            "-0.003 -0.002 -0.001 00.001 0.002 0.003 0.004 0.005 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired \n",
            "-0.008 -0.006 -0.004 -0.002 00.002 0.004 0.006 0.008 0.01 \n",
            "0 2 4 6 8 10 12 14 16 \n",
            "Time Acceleration Neural Desired                       \n",
            "Fig. 7(a). Comparison Between Neural and Desired fo r time period and the \n",
            "                              corresponding maximum  response of Uttarkashi earthquake at           \n",
            "                              Barkot in NW directio n ( 620 points ) \n",
            " \n",
            "Fig. 7(b). Comparison Between Neural and Desired fo r time period and the    \n",
            "             corresponding maximum response of Utta rkashi earthquake at \n",
            "                              Tehri in NW direction  ( From weights of 620 points ) 00.001 0.002 0.003 0.004 0.005 0.006 0.007 \n",
            "0 2 4 6 8 10 12 \n",
            "Time Period Acceleration Neural Desired \n",
            "00.001 0.002 0.003 0.004 0.005 0.006 0.007 \n",
            "0 2 4 6 8 10 12 \n",
            "Time period Acceleration Neural Desired \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc60_mlQPHF_",
        "outputId": "8535b7e4-4047-4b57-dbf7-c04c001e21db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.50)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.25.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.54)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.7)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3jHk7R2gvba",
        "outputId": "01e18ff1-fcad-4e3b-84ba-2c0ba3b68480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24311"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split document into chunks"
      ],
      "metadata": {
        "id": "FTFjffTwg7cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 2048\n",
        "chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]"
      ],
      "metadata": {
        "id": "ldRbTLKTgwDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load into a FAISS vectorstore"
      ],
      "metadata": {
        "id": "q9sLt1fthYE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Splitting the text into manageable chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "text_chunks = text_splitter.split_text(data)\n",
        "\n",
        "# Converting the chunks into a list of Document objects\n",
        "documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
        "\n",
        "# Initializing the OpenAIEmbeddings with your API key\n",
        "openai_api_key = \"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\"\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "# Creating a FAISS vector store\n",
        "vectorstore = FAISS.from_documents(documents, embedding=embeddings)"
      ],
      "metadata": {
        "id": "KSR3HLiwOzv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bE47NF5hGc1",
        "outputId": "4272bbbd-ba6c-44bb-87b1-fa40e16b9d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iST3G-nzhOaJ",
        "outputId": "c1534b42-ca00-4974-be51-0ddc60bb6ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x78a8f8eae3e0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x78a8f8e63fa0>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFtRAd0GR-VR",
        "outputId": "a01fb5eb-5390-4d95-9a76-5ff67e14c982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.50)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine context and question in a prompt and generate response"
      ],
      "metadata": {
        "id": "70BPVENSQouF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Ensure that the OpenAI API key is set as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the OpenAI Chat model (e.g., GPT-4-turbo)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# Create a retriever from the FAISS vector store\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Create the RetrievalQA chain using the chat model and retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
        "\n",
        "# Ask a question based on the indexed PDF context\n",
        "query = \"What are the key findings in the document?\"\n",
        "result = qa_chain.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNcLlnqfQTDK",
        "outputId": "53c5b0b7-b3b6-487a-83ef-28d82632841d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key findings in the document include:\n",
            "\n",
            "1. The use of an Artificial Neural Network (ANN) to compute the structural response of a single degree of freedom system subjected to Indian earthquakes, specifically using ground motion data from the Chamoli and Uttarkashi earthquakes.\n",
            "\n",
            "2. The ANN model was trained with data from these earthquakes and was able to predict the maximum response for various time periods effectively.\n",
            "\n",
            "3. The trained ANN model's weights were stored and successfully used to predict responses for different time periods for another earthquake scenario, demonstrating good agreement between the ANN model predictions and the desired results.\n",
            "\n",
            "These findings highlight the effectiveness of using ANN in earthquake engineering for predicting structural responses to seismic activities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Initialize the OpenAI Chat model\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# Create a retriever from your vector store\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Create the RetrievalQA chain using the chat model and retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
        "\n",
        "# List to store questions and answers\n",
        "qa_pairs = []\n",
        "\n",
        "# Define a list of questions, ensuring each is separated by a comma\n",
        "questions = [\n",
        "    \"What is the primary purpose of using Artificial Neural Networks (ANN) in this study?\",\n",
        "    \"What earthquake data was used to train the ANN model?\",\n",
        "    \"Summarize the document in a few sentences.\",\n",
        "    \"How does a building’s natural frequency affect its response to earthquakes?\",\n",
        "    \"What method is used in the paper for ANN training?\",\n",
        "    \"What are some previous applications of ANN models mentioned in the study?\"\n",
        "]\n",
        "\n",
        "# Ask each question and collect the answers\n",
        "for question in questions:\n",
        "    answer = qa_chain.run(question)\n",
        "    qa_pairs.append({\"Question\": question, \"Answer\": answer})\n",
        "\n",
        "# Create a DataFrame from the question-answer pairs\n",
        "qa_df = pd.DataFrame(qa_pairs)\n",
        "\n",
        "# Save the DataFrame to a CSV file named \"OpenAIAnswers.csv\"\n",
        "csv_filename = \"OpenAIAnswers.csv\"\n",
        "qa_df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "qa_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "J780SEiZSjR6",
        "outputId": "c63eba0e-6b06-48f1-ee76-d99adeaa6941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question  \\\n",
              "0  What is the primary purpose of using Artificia...   \n",
              "1  What earthquake data was used to train the ANN...   \n",
              "2         Summarize the document in a few sentences.   \n",
              "3  How does a building’s natural frequency affect...   \n",
              "4  What method is used in the paper for ANN train...   \n",
              "5  What are some previous applications of ANN mod...   \n",
              "\n",
              "                                              Answer  \n",
              "0  The primary purpose of using Artificial Neural...  \n",
              "1  The ANN model was trained using earthquake dat...  \n",
              "2  The document discusses the use of Artificial N...  \n",
              "3  A building's natural frequency plays a crucial...  \n",
              "4  The paper uses Artificial Neural Networks (ANN...  \n",
              "5  The study mentions several previous applicatio...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a941f7bc-17ee-424d-a7d7-54cfb5250ca3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the primary purpose of using Artificia...</td>\n",
              "      <td>The primary purpose of using Artificial Neural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What earthquake data was used to train the ANN...</td>\n",
              "      <td>The ANN model was trained using earthquake dat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Summarize the document in a few sentences.</td>\n",
              "      <td>The document discusses the use of Artificial N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does a building’s natural frequency affect...</td>\n",
              "      <td>A building's natural frequency plays a crucial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What method is used in the paper for ANN train...</td>\n",
              "      <td>The paper uses Artificial Neural Networks (ANN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What are some previous applications of ANN mod...</td>\n",
              "      <td>The study mentions several previous applicatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a941f7bc-17ee-424d-a7d7-54cfb5250ca3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a941f7bc-17ee-424d-a7d7-54cfb5250ca3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a941f7bc-17ee-424d-a7d7-54cfb5250ca3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51dc6062-b66f-4714-91fa-921b3f72ec5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51dc6062-b66f-4714-91fa-921b3f72ec5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51dc6062-b66f-4714-91fa-921b3f72ec5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_64a608f4-0295-4046-8671-3177593dea35\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('qa_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64a608f4-0295-4046-8671-3177593dea35 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('qa_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "qa_df",
              "summary": "{\n  \"name\": \"qa_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"What is the primary purpose of using Artificial Neural Networks (ANN) in this study?\",\n          \"What earthquake data was used to train the ANN model?\",\n          \"What are some previous applications of ANN models mentioned in the study?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"The primary purpose of using Artificial Neural Networks (ANN) in this study is to compute the response of structural systems subject to Indian earthquakes, specifically using ground motion data from Chamoli and Uttarkashi. The ANN models are trained with earthquake data to predict the dynamic responses of structures to various earthquake intensities without the need for traditional mathematical analysis. This approach leverages the ANN's ability to handle partially inaccurate data and its excellent learning capacity, making it a powerful tool for simulating and predicting structural responses under seismic activities.\",\n          \"The ANN model was trained using earthquake data from Chamoli and Uttarkashi ground motions.\",\n          \"The study mentions several previous applications of Artificial Neural Networks (ANN) models, including:\\n\\n1. Detection of simulated damage in structures.\\n2. Applications in concrete structures.\\n3. Damage detection in a bridge truss using ANN with multilayer perceptron architectures applied to numerically simulated data.\\n4. Structural damage detection and system identification in other studies referenced as [15]-[17].\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display each question and answer individually\n",
        "for index, row in qa_df.iterrows():\n",
        "    print(f\"Question {index + 1}: {row['Question']}\")\n",
        "    print(f\"Answer {index + 1}: {row['Answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFH8F9iBVJCj",
        "outputId": "9154a585-0175-4eea-898f-1caf7f1f2ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: What is the primary purpose of using Artificial Neural Networks (ANN) in this study?\n",
            "Answer 1: The primary purpose of using Artificial Neural Networks (ANN) in this study is to compute the response of structural systems subject to Indian earthquakes, specifically using ground motion data from Chamoli and Uttarkashi. The ANN models are trained with earthquake data to predict the dynamic responses of structures to various earthquake intensities without the need for traditional mathematical analysis. This approach leverages the ANN's ability to handle partially inaccurate data and its excellent learning capacity, making it a powerful tool for simulating and predicting structural responses under seismic activities.\n",
            "\n",
            "Question 2: What earthquake data was used to train the ANN model?\n",
            "Answer 2: The ANN model was trained using earthquake data from Chamoli and Uttarkashi ground motions.\n",
            "\n",
            "Question 3: Summarize the document in a few sentences.\n",
            "Answer 3: The document discusses the use of Artificial Neural Network (ANN) models to predict the structural response of systems subjected to earthquakes in India, specifically using data from Chamoli and Uttarkashi. The ANN is trained with real earthquake data and then used to simulate various earthquake intensities. The results, which show a good comparison between the ANN model predictions and desired outcomes, are stored and depicted in figures within the document. The study highlights the potential of ANN in improving responses to earthquake-related challenges.\n",
            "\n",
            "Question 4: How does a building’s natural frequency affect its response to earthquakes?\n",
            "Answer 4: A building's natural frequency plays a crucial role in determining its response to earthquakes. Each building has a specific natural frequency, which is the rate at which it tends to vibrate if disturbed. During an earthquake, the ground shakes at various frequencies. If the frequency of the ground shaking matches the building's natural frequency, this can lead to a phenomenon known as resonance.\n",
            "\n",
            "Resonance occurs when the oscillations of the earthquake's seismic waves are in sync with the building's natural frequency, causing the building to experience significantly increased amplitude of vibrations. This amplified vibration can lead to greater swaying and potentially more structural damage if the building is not designed to handle such stresses. Therefore, understanding and appropriately accounting for a building's natural frequency is crucial in earthquake engineering to enhance the building's resilience to seismic activities.\n",
            "\n",
            "Question 5: What method is used in the paper for ANN training?\n",
            "Answer 5: The paper uses Artificial Neural Networks (ANN) for training, specifically with and without damping, to compute the response of a structural system subject to Indian earthquakes using Chamoli and Uttarkashi ground motion data. The ANN is first trained with a single real earthquake data, and the converged weight matrices from this training are then used to predict the direct response of the structure to other earthquakes without requiring further mathematical analysis.\n",
            "\n",
            "Question 6: What are some previous applications of ANN models mentioned in the study?\n",
            "Answer 6: The study mentions several previous applications of Artificial Neural Networks (ANN) models, including:\n",
            "\n",
            "1. Detection of simulated damage in structures.\n",
            "2. Applications in concrete structures.\n",
            "3. Damage detection in a bridge truss using ANN with multilayer perceptron architectures applied to numerically simulated data.\n",
            "4. Structural damage detection and system identification in other studies referenced as [15]-[17].\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B: Write a chatbot prompt to iteratively create a sequence of chats on one particular custom data.\n",
        "\n",
        "1. The chatbot should be able to answer the questions based on the text data or multiple documents.\n",
        "\n",
        "2. The chatbot should save the conversation in the memory.\n",
        "\n",
        "2. Summarize the chats at the end of the conversation."
      ],
      "metadata": {
        "id": "TaHtiPfXTZ9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot prompt for iterative conversation\n",
        "\n",
        "# Creating a list to store all chat interactions (questions and answers)\n",
        "chat_history = []\n",
        "\n",
        "# Function to handle a question and generate an answer\n",
        "def chat_with_custom_data(question):\n",
        "    # Using the QA chain or any custom method to get an answer\n",
        "    answer = qa_chain.run(question)\n",
        "\n",
        "    # Adding the question and answer to the chat history\n",
        "    chat_history.append({\"Question\": question, \"Answer\": answer})\n",
        "\n",
        "    # Printing the answer\n",
        "    print(f\"Answer: {answer}\\n\")\n",
        "\n",
        "# Introduction and instructions for the conversation\n",
        "print(\"Welcome to the custom data chatbot. Ask any questions about the data.\")\n",
        "print(\"Type 'end' to finish the conversation.\")\n",
        "\n",
        "# Conversation loop\n",
        "while True:\n",
        "    # Get the user's question input\n",
        "    question = input(\"Ask your question: \").strip()\n",
        "\n",
        "    # Check if the user wants to end the conversation\n",
        "    if question.lower() == \"end\":\n",
        "        break\n",
        "\n",
        "    # Generating an answer for the given question\n",
        "    chat_with_custom_data(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CBDAbkoTcxh",
        "outputId": "651763fe-cdb8-4331-a731-4c6f93aff259"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the custom data chatbot. Ask any questions about the data.\n",
            "Type 'end' to finish the conversation.\n",
            "Ask your question: Which data set was used to validate the ANN model's predictions for time periods and maximum responses?\n",
            "Answer: The ANN model's predictions for time periods and maximum responses were validated using real earthquake data from a location that was not included in the training data set.\n",
            "\n",
            "Ask your question: How many hidden layer nodes were found to be optimal for the ANN model's hidden layer?\n",
            "Answer: 10 nodes in the hidden layer were found to be optimal for the ANN model's hidden layer.\n",
            "\n",
            "Ask your question: What was the goal of using time period versus maximum response data in the ANN model?\n",
            "Answer: The goal of using time period versus maximum response data in the ANN model was to train the model to predict the maximum response of a building during different time periods of an earthquake. This approach allows for the assessment of the structural system's response to seismic events, enhancing the ability to predict and ensure the safety of buildings in the event of future earthquakes.\n",
            "\n",
            "Ask your question: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdkyHupAmhk1",
        "outputId": "f3212130-196f-4198-fb38-2499105da52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.0 pypdfium2-4.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pdfplumber\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text_content = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text_content.append(page.extract_text())\n",
        "    return \"\\n\".join(text_content)\n",
        "\n",
        "# Load the PDF content into a variable (example PDF file path)\n",
        "pdf_file_path = '/content/drive/MyDrive/Sample.pdf'\n",
        "pdf_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Initialize the conversation memory buffer\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Simulate initial conversation to add context\n",
        "memory.chat_memory.add_user_message(\"I have some data related to research paper that I recently read, and I'd like to analyze it. Here's some information:\")\n",
        "memory.chat_memory.add_ai_message(f\"Sure, I see. Please feel free to ask any questions you may have about the data:\\n{pdf_text}\")\n",
        "\n",
        "# Initialize GPT-4 model for conversation\n",
        "conversation = ConversationChain(\n",
        "    llm=ChatOpenAI(model=\"gpt-4\"),\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "# Function to save conversation memory to a CSV file\n",
        "def save_memory_to_csv(memory, file_path=\"chat_history.csv\"):\n",
        "    with open(file_path, \"w\", newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Question\", \"Answer\"])  # CSV Headers\n",
        "        lines = memory.chat_memory.messages\n",
        "        for i in range(0, len(lines) - 1, 2):\n",
        "            question = lines[i].content.replace(\"Human:\", \"\").strip()\n",
        "            answer = lines[i + 1].content.replace(\"AI:\", \"\").strip()\n",
        "            writer.writerow([question, answer])\n",
        "\n",
        "# Introduction and instructions for the conversation\n",
        "print(\"Welcome to the GPT-4 chatbot. Ask any questions about your provided data.\")\n",
        "print(\"Type 'end' to finish the conversation.\")\n",
        "\n",
        "# Conversation loop\n",
        "while True:\n",
        "    # Get the user's question input\n",
        "    question = input(\"Ask your question: \").strip()\n",
        "\n",
        "    # Check if the user wants to end the conversation\n",
        "    if question.lower() == \"end\":\n",
        "        break\n",
        "\n",
        "    # Generate an answer using the conversation chain\n",
        "    response = conversation.predict(input=question)\n",
        "    print(f\"Answer: {response}\\n\")\n",
        "\n",
        "# Saving the chat history to a CSV file using the conversation memory buffer\n",
        "save_memory_to_csv(memory)\n",
        "\n",
        "# Print a summarized conversation history\n",
        "print(\"\\nConversation Summary:\")\n",
        "for i, message in enumerate(memory.chat_memory.messages):\n",
        "    role = \"Q\" if i % 2 == 0 else \"A\"\n",
        "    print(f\"{role}: {message.content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xcgrTmGW9_K",
        "outputId": "696e8780-f3eb-4536-e24b-5662b2a8ec0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the GPT-4 chatbot. Ask any questions about your provided data.\n",
            "Type 'end' to finish the conversation.\n",
            "Ask your question: What is the error backpropagation training algorithm (EBPTA), and how is it used in this study?\n",
            "Answer: The Error Back Propagation Training Algorithm (EBPTA) is a method used in training artificial neural networks. In this study, it is used to adjust the weights in the network. The weights are the strengths of the connections between the neurons in the network, and adjusting them changes the input/output behavior of the network.\n",
            "\n",
            "The process works as follows:\n",
            "\n",
            "1. The algorithm is given a set of training pairs, which include inputs and desired outputs.\n",
            "2. The algorithm computes an error value for the present neural network.\n",
            "3. The error signal terms of the output and hidden layers are calculated.\n",
            "4. The weights of the output layer and hidden layer are adjusted based on these error signal terms and a learning constant.\n",
            "\n",
            "In the context of this research paper on predicting structural system responses to earthquakes, the EBPTA is used to train the neural network on ground acceleration and response data from earthquakes. Once trained, the network can be used to simulate responses for earthquakes of various intensities.\n",
            "\n",
            "Ask your question: What did the response predictions show for varying earthquake intensities after training with the Chamoli earthquake data?\n",
            "Answer: After training with the Chamoli earthquake data, the Artificial Neural Network (ANN) model was able to predict responses for earthquakes of various intensities. The trained model was tested for 80% and 120% of the Chamoli earthquake's intensity. The results showed a good match between the predicted responses and the actual responses.\n",
            "\n",
            "For instance, when tested with 80% of the Chamoli earthquake at Barkot (NE) for a frequency parameter ω=0.01, the maximum response was 0.135079 m/sec/sec. Similarly, for 120% of the Chamoli earthquake at Barkot (NE) for ω=0.5, the maximum response was 0.20260 m/sec/sec. These results suggest that the ANN model can accurately predict the responses of structural systems to earthquakes of various intensities. \n",
            "\n",
            "The model also showed its ability to predict responses to earthquakes not used in the training phase. This means that it can potentially predict the safety of structural systems in case of future earthquakes.\n",
            "\n",
            "Ask your question: Which parameters define the natural frequency of a structure, as per the document?\n",
            "Answer: The natural frequency of a structure, denoted as ω² in the document, is determined by two key parameters: the stiffness of the structure, represented as K, and the mass of the structure, represented as M. The natural frequency parameter is calculated as ω² = K/M. \n",
            "\n",
            "This natural frequency is significant because if the ground shakes with the same frequency as a building's natural frequency, it can cause the building to sway with increasing amplitude, placing the most strain on the components of the building and potentially leading to collapse. This is why understanding and predicting the natural frequency of a building is crucial in earthquake-prone areas.\n",
            "\n",
            "Ask your question: How many hidden layer nodes were found to be optimal for the ANN model's hidden layer?\n",
            "Answer: The researchers found that using between 5 to 20 nodes in the hidden layer of the Artificial Neural Network (ANN) model produced almost the same good results. However, for the sake of generating further results, they decided to use 10 nodes in the hidden layer. This was found to be sufficient for accurate prediction of the structural responses to various intensity earthquakes.\n",
            "\n",
            "Ask your question: Which data set was used to validate the ANN model's predictions for time periods and maximum responses?\n",
            "Answer: The Uttarkashi earthquake at Tehri in NW direction was used to validate the ANN model's predictions for time periods and maximum responses. This data set was not used during the training phase. The ANN model, which was trained with the time periods and corresponding maximum responses from the Uttarkashi earthquake at Barkot in NW direction, was able to predict the maximum response directly to the corresponding time period for the Tehri earthquake. The results showed good agreement between the model's predictions and the actual data.\n",
            "\n",
            "Ask your question: end\n",
            "\n",
            "Conversation Summary:\n",
            "Q: I have some data related to research paper that I recently read, and I'd like to analyze it. Here's some information:\n",
            "\n",
            "A: Sure, I see. Please feel free to ask any questions you may have about the data:\n",
            "Response Prediction of Structural System Subject to Earthquake\n",
            "Motions using Artificial Neural Network\n",
            "S. Chakraverty*, T. Marwala** , Pallavi Gupta* and Thando Tettey**\n",
            "*B.P.P.P. Division, Central Building Research Institute\n",
            "Roorkee-247 667, Uttaranchal, India\n",
            "e-mail :sne_chak@yahoo.com\n",
            "**School of Electrical and Information Engineering,\n",
            "University of the Witwatersrand, Private Bag 3\n",
            "Wits, 2050,Republic of South Africa\n",
            "Abstract\n",
            "This paper uses Artificial Neural Network (ANN) models to compute response of\n",
            "structural system subject to Indian earthquakes at Chamoli and Uttarkashi\n",
            "ground motion data. The system is first trained for a single real earthquake data.\n",
            "The trained ANN architecture is then used to simulate earthquakes with various\n",
            "intensities and it was found that the predicted responses given by ANN model\n",
            "are accurate for practical purposes. When the ANN is trained by a part of the\n",
            "ground motion data, it can also identify the responses of the structural system\n",
            "well. In this way the safeness of the structural systems may be predicted in case\n",
            "of future earthquakes without waiting for the earthquake to occur for the lessons.\n",
            "Time period and the corresponding maximum response of the building for an\n",
            "earthquake has been evaluated, which is again trained to predict the maximum\n",
            "response of the building at different time periods. The trained time period versus\n",
            "maximum response ANN model is also tested for real earthquake data of other\n",
            "place, which was not used in the training and was found to be in good\n",
            "agreement.\n",
            "Keywords : Earthquake, Neural Network, Frequency, Structure, Building.\n",
            "1 Introduction\n",
            "Real earthquake ground motion at a particular building site is very complicated.\n",
            "The response of a building to an earthquake is dynamic and for a dynamic\n",
            "response, the building is subjected to a vibratory shaking of the base. Exactly\n",
            "how a building responds is complex and depends on the amplitude and\n",
            "frequency of vibration along with the material and design of the building. All\n",
            "buildings have a \"natural frequency\" associated with them. If strain is placed on\n",
            "to the structure and then let it snap back into equilibrium, it will sway back and\n",
            "forth with an amplitude that decays with time. If the ground shakes with the same\n",
            "frequency as a building's natural frequency, it will cause the amplitude of sway to\n",
            "get larger and larger such that, the ground shaking is in resonance with the\n",
            "building's natural frequency. This produces the most strain on the components of\n",
            "the building and can quickly cause the building to collapse. Powerful technique of\n",
            "Artificial Neural Network (ANN) has been used to model the problem for one\n",
            "storey structure. Among the different types of ANN, the feedforward, multilayer,\n",
            "supervised neural network with error back propagation algorithm, the BPN [1] is\n",
            "the most frequently applied NN model. Dynamic response of a structure to strong\n",
            "earthquake ground motion may be investigated by different methods. The\n",
            "method, that has been used here, is to create a trained black box containing the\n",
            "characteristics of the structure and of the earthquake motion which can predict\n",
            "the dynamic response for any other earthquake for a particular structure.\n",
            "Artificial Neural Network (ANN) have gradually been established as a powerful\n",
            "soft computing tool in various fields because of their excellent learning capacity\n",
            "and their high tolerance to partially inaccurate data. ANN has, recently been\n",
            "applied to assess damage in structures. Stefano et al.[3] used probabilistic\n",
            "Neural Networks for seismic damage prediction. Many methods viz. [4]-[9] were\n",
            "introduced for response estimation and for structural control. Zhao et al.[10]\n",
            "applied a counter-propagation NN to locate damage in beams and frames.\n",
            "KuZniar and Waszczyszyn [11] simulated the dynamic response for prefabricated\n",
            "building using ANN. Elkordy et al.[12] used a back-propagation neural network\n",
            "with modal shapes in the input layer to detect the simulated damage of\n",
            "structures. Muhammad [13] gives certain ANN applications in concrete\n",
            "structures. Pandey and Barai [14] detected damage in a bridge truss by applying\n",
            "ANN of multilayer perceptron architectures to numerically simulated data. Some\n",
            "studies such as [15]-[17] used artificial neural network for structural damage\n",
            "detection and system identification.\n",
            "In the present paper, the Chamoli earthquake ground acceleration at Barkot (NE)\n",
            "and Uttarkashi earthquake ground acceleration recorded at Barkot (NE and NW)\n",
            "have been considered based on the authors' previous study [18]. From their\n",
            "ground acceleration the responses are computed using the usual procedure.\n",
            "Then the ground acceleration and the corresponding response are trained using\n",
            "Artificial Neural Network (ANN) with and without damping. After training the\n",
            "network with one earthquake, the converged weight matrices are stored. In order\n",
            "to show the power of these converged (trained) networks other earthquakes are\n",
            "used as input to predict the direct response of the structure without using any\n",
            "mathematical analysis of the response prediction. Similarly, the various time\n",
            "periods of one earthquake and its corresponding maximum responses are\n",
            "trained. Then the converged weights are used to predict the maximum response\n",
            "directly to the corresponding time period. Various other results related to use of\n",
            "these trained networks are discussed for future / other earthquakes.\n",
            "2 Artificial Neural Network\n",
            "Artificial neural systems are present day machines that have great potential to\n",
            "improve the quality of our life. Advances have been made in applying such\n",
            "systems for problems found difficult for traditional computation. A neural network\n",
            "is a parallel, distributed information processing structure consists of processing\n",
            "elements called neurons, which are interconnected and unidirectional signal\n",
            "channels called connections. The general structure of the network that have\n",
            "been used here is given in Fig.1. the structure consists of three layers : the input\n",
            "layer, the hidden layer and the output layer. The input layer is made up of one or\n",
            "more neurons or processing elements that collectively represent the information\n",
            "in a particular pattern of a training set. The hidden layer also consists of one or\n",
            "more neurons. Its purpose is simply to transform the information from the input\n",
            "layer to prepare it for the output layer. The output layer, which has one or more\n",
            "neurons, uses input from the hidden layer (which is a transformation of the input\n",
            "layer) to produce an output value for the entire network. The output is used to\n",
            "interpret the training and classification results of the network. The processing\n",
            "elements or neurons are connected to each other by adjustable weights. The\n",
            "input/output behaviour of the network changes if the weights are changed. So,\n",
            "the weights of the net may be chosen in such a way so as to achieve a desired\n",
            "output. To satisfy this goal, systematic ways of adjusting the weights have to be\n",
            "developed, which are known as training or learning algorithm.\n",
            "Output Units\n",
            "O\n",
            "k\n",
            "O\n",
            "1\n",
            "P\n",
            "j Hidden units\n",
            "P\n",
            "1\n",
            "Z\n",
            "j\n",
            "Z\n",
            "1\n",
            "Input Units\n",
            "Fig.1. Layered Feedforward Neural Network\n",
            "3 Error Back Propagation Training Algorithm (EBPTA)\n",
            "Here, Error Back Propagation Training algorithm and feedforward recall with one\n",
            "hidden layer has been used. In Fig. 1, Z, P and O are input, hidden and output\n",
            "i j k\n",
            "layer respectively. The weights between input and hidden layers are denoted by\n",
            "ν and the weights between hidden and output layers are denoted by W . The\n",
            "ji kj\n",
            "procedure may easily be written down for the processing of this algorithm.\n",
            "Given R training pairs\n",
            "{Z ,d ;Z ,d ;.........Z ,d }\n",
            "1 1 2 2 R R\n",
            "where Z (Ix1) are input and d (Kx1) are desired values for the given inputs, the\n",
            "i i\n",
            "error value is computed as\n",
            "1\n",
            "E = (d −O )2 , k =1,2,.....K\n",
            "k k\n",
            "2\n",
            "for the present neural network as shown in Fig. 1.\n",
            "The error signal terms of the output (δ ) and hidden layers (δ ) are written\n",
            "Ok Pj\n",
            "respectively as,\n",
            "2\n",
            "δ =0.5*(d −O )(1−O ), k =1,2,........K\n",
            "Ok k k k\n",
            "K\n",
            "2\n",
            "δ = 0.5*(1−P ) ∑ δ W , j =1,2,....J\n",
            "Pj j Ok Pj\n",
            "k=1\n",
            "Consequently, output layer weights (W ) and hidden layer weights (δ ) are\n",
            "kj ji\n",
            "adjusted as,\n",
            "(New) (Old)\n",
            "ν =ν +βδ Z , j=1,2.......J and i =1,2,.......I\n",
            "ji ji Pj i\n",
            "(New) (Old)\n",
            "W = W +βδ P , k =1,2.....K and j=1,2,.....J\n",
            "kj kj Ok j\n",
            "Where, β is the learning constant.\n",
            "4 Response Prediction\n",
            "The basic idea behind the proposed methodology is to predict the structural\n",
            "response of single degree of freedom system i.e. single storey building subject to\n",
            "various earthquake forces. Two cases viz without damping and with damping\n",
            "have been considered for the analysis.\n",
            "Case(i) : Without damping\n",
            "Let M be the mass of the generalized one storey structure, K the stiffness of the\n",
            "structure and x be the displacement relative to the ground then the equation of\n",
            "motion may be written as:\n",
            "&& &&\n",
            "Mx+Kx = −Ma (1)\n",
            "&&\n",
            "x =Responseacceleration,\n",
            "x =Displacement,\n",
            "&&\n",
            "a =Groundacceleration.\n",
            "where,\n",
            "Equation (1) may be written as,\n",
            "& x& +ω2x = −a&& (2)\n",
            "Where ω2=K/M, is the natural frequency parameter of the undamped structure.\n",
            "The solution of equation (2) [Ref. 2] is given by\n",
            "t\n",
            "1\n",
            "&&\n",
            "x(t) = − ∫a(τ)sin[ω(t−τ)]dτ (3)\n",
            "ω\n",
            "0\n",
            "From this solution the response of the structure viz. acceleration is obtained for\n",
            "no damping.\n",
            "Case (ii) : With damping\n",
            "Let M be the mass of the generalized one storey structure, K the stiffness of the\n",
            "structure, C the damping and x be the displacement relative to the ground then\n",
            "the equation of motion may be written as:\n",
            "M&x& +Cx& + Kx = −Ma&& (4)\n",
            "where\n",
            "&&\n",
            "x =Responseacceleration,\n",
            "&\n",
            "x=Response velocity,\n",
            "x =Displacement,\n",
            "&&\n",
            "a =Groundacceleration.\n",
            "Equation (4) may be written as,\n",
            "&x& +2ξωx& +ω2x = −a&& (5)\n",
            "Where ξω = C/2M and ω2=K/M, is the natural frequency parameter of the\n",
            "undamped structure.\n",
            "The solution of equation (5) [Ref.2] is given by\n",
            "t\n",
            "1\n",
            "&&\n",
            "x(t) = − ∫a(τ)exp[−ξω(t−τ)]sin[ω(t−τ)]dτ (6)\n",
            "ω\n",
            "0\n",
            "From this solution the response of the structure viz. acceleration is obtained for\n",
            "damping.\n",
            "Now, the neural network architecture is constructed, taking ground acceleration\n",
            "as input and the response obtained from the above solution is taken as output for\n",
            "each time step. Therefore, the whole network consists of one input layer, one\n",
            "hidden layer with varying nodes and one output layer as shown in Fig.1. Similarly\n",
            "for the other problem of time period vs. maximum response the input and output\n",
            "layer contain the time period and the corresponding maximum response\n",
            "respectively at each interval for the particular structure.\n",
            "5 Numerical Results and Discussions\n",
            "For the present study two Indian earthquakes viz. the Chamoli Earthquake (max.\n",
            "ground acceleration =0.16885 m/sec/sec) at Barkot in NE (north–east) direction\n",
            "shown in Fig.2(a) and the Uttarkashi earthquake (maximum ground acceleration\n",
            "= 0.931 m/sec/sec) at Barkot in NE (north–east) and NW (north-west) direction\n",
            "as given in Figs. 2(b) and 2(c) have been considered for training and testing.\n",
            "Initially, the system without damping is studied and for that the ground\n",
            "acceleration of Chamoli earthquake at Barkot (NE) was used to compute the\n",
            "response for single storey structure using usual procedure from Eq.(3). The\n",
            "obtained response and the ground acceleration is trained first for the assumed\n",
            "frequency parameters ω=0.5 and ω=0.01 for time range 0 to 14.92 sec.(748 data\n",
            "points) for the mentioned earthquake. Simulations have been done for different\n",
            "hidden layer nodes and it was seen that the response result is almost same and\n",
            "good for 5 to 20 nodes in the hidden layer. However, 10 hidden layer nodes are\n",
            "used here to generate further results.\n",
            "After training ground acceleration and response data for Chamoli earthquake at\n",
            "Barkot (NE) for 10 nodes in hidden layer, the weights are stored and they are\n",
            "used to predict responses for various intensity earthquakes. The plot in Fig. 3(a)\n",
            "shows response comparison between neural and desired for the 80% of Chamoli\n",
            "earthquake at Barkot (NE) for ω=0.01(maximum response=0.135079m/sec/sec).\n",
            "Similarly, the response comparison for 120% Chamoli earthquake at Barkot (NE)\n",
            "for ω=0.5 (Maximum response=0.20260 m/sec/sec) is shown in Fig 3(b).\n",
            "Next, a part of the ground acceleration is used for the training and it will be\n",
            "shown that the present ANN can predict the whole period of the response using\n",
            "the trained ANN by the part of the data. So, the ground acceleration and\n",
            "response data with Chamoli earthquake is trained for an example with the time\n",
            "range 0 to 10.96 sec.(550 data points). Its weights are stored to find the\n",
            "response for the time range 0 to 14.92 sec. (whole period) at different\n",
            "percentages of the earthquake in order to test the network learning for the points\n",
            "outside the training set. Figs. 4(a) and 4(b) show the response comparison\n",
            "between neural and desired for ω=0.01, (maximum response=0.168849\n",
            "m/sec/sec) and for ω=0.5 (maximum response=0.168841 m/sec/sec) at the time\n",
            "range 0 to 10.96 sec. The response comparison between neural and desired for\n",
            "ω=0.01 with 120% of the earthquake force (maximum response = 0.20260\n",
            "m/sec/sec) from the time range 0 to 14.92 sec.(748 data points) is incorporated\n",
            "in Fig. 5(a). It is obtained from the weights of the trained data for the time range 0\n",
            "to 10.96 sec. (550 data points). From the same weights, neural responses for\n",
            "80% of earthquake force, is computed with ω=0.5(maximum response=0.135073\n",
            "m/sec/sec), for the time range 0 to 14.92 sec. (748 data points) and it is plotted in\n",
            "Fig. 5(b).\n",
            "The system with damping is then considered and for this, first from the ground\n",
            "acceleration of Chamoli Earthquake at Barkot (NE), the response is computed\n",
            "using Eq.(6). The obtained responses and the ground acceleration are trained by\n",
            "the said ANN model for an example structural system with frequency parameter\n",
            "ω= 0.68981 and damping = 1.58033. This training was done for the total time\n",
            "range 0 to 14.92 sec. (748 points, earthquake period). Plot of 100% response\n",
            "comparison between neural and desired for Chamoli Earthquake at barkot (NE)\n",
            "is shown in Fig. 6(a). After training ground acceleration and response data for\n",
            "Chamoli Earthquake for various nodes in the hidden layer it was confirmed that\n",
            "10 nodes are again sufficient for the prediction. So, the weights corresponding to\n",
            "10 hidden nodes are stored and they are used to predict responses for various\n",
            "intensity earthquakes. The response for 50% (ω= 0.68981, damping = 1.58033\n",
            "and maximum response = 0.00375 m/sec/sec) of the Chamoli Earthquake at\n",
            "Barkot (NE) and its comparison with the desired response are shown in Fig. 6(b).\n",
            "Similarly, the response comparison between neural and desired is shown in Fig.\n",
            "6(c) (ω= 0.68981, damping = 1.58033 and maximum response for 120% =\n",
            "0.00910 m/sec/sec) for 120% of earthquake acceleration.\n",
            "Finally, the Uttarkashi earthquake at Barkot (NW) ground acceleration is used\n",
            "with damping = 0.05, at different time periods ( t = 1/omega) ranging from 0.5 to\n",
            "10 with an interval of 0.02 (620 data points) for evaluating the maximum\n",
            "responses corresponding to each time period using Eq. (6). The obtained time\n",
            "periods and the corresponding responses are trained and then the converged\n",
            "weights are stored. The comparison between neural and desired results is shown\n",
            "in Fig. 7(a). The stored weights were then used to predict the response for\n",
            "different time periods lying in the same range of 0.5 to 10 but at different time\n",
            "interval of 0.5 for another earthquake such as Uttarkashi earthquake at Tehri\n",
            "(NW), The results are depicted in Fig. 7(b) showing good comparison between\n",
            "ANN model and desired results.\n",
            "6 Conclusions\n",
            "This paper uses the powerful soft computing technique (Artificial Neural Network)\n",
            "to compute structural response of single degree of freedom system subject to\n",
            "Indian earthquakes at Chamoli and Uttarkashi ground motion data. Also this\n",
            "technique is used to predict the maximum response corresponding to various\n",
            "time periods. It is shown here that once the training is done then the trained\n",
            "architecture may be used to simulate for various intensity earthquakes, thereby\n",
            "showing the responses of the system which depend upon the structural\n",
            "properties (mass and stiffness) of the structure. If the network is trained for\n",
            "various time periods of one earthquake and its corresponding maximum\n",
            "responses then the model can predict the maximum response directly to the\n",
            "corresponding time period for any other earthquake that had not been used\n",
            "during the training. In this way the safety of the structural systems may be\n",
            "predicted in case of future earthquakes.\n",
            "Acknowledgements\n",
            "The authors would like to thank Department of Science and Technology, India for\n",
            "funding and Director C.B.R.I. for giving permission to publish this paper.\n",
            "References\n",
            "[1] D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning international\n",
            "representation by error propagation. In Parallel Distributed Processing, D.E.\n",
            "Rumelhart, et al. (eds). (The MIT Press: Cambridge, MA, 1986).\n",
            "[2] N.M. Newmark, E. Rosenblueth, Fundamentals of Earthquake Engineering,\n",
            "(Prentice-Hall, Inc. Englewood Cliffs, N.J, 1971).\n",
            "[3] A. De Stefano, D.Sabia, L.Sabia, Probabilistic Neural Networks for Seismic\n",
            "Damage Mechanisms Prediction, Earthquake Engineering and Structural\n",
            "Dynamics, Vol. 28, No. 8 (1999) 807-\n",
            "[4] A. Kallassy, A new neural Network for Response Estimation, Computers and\n",
            "Structures, Vol. 81, No. 26-27 (2003), 2417-2429\n",
            "[5] A. Zhang, L. Zhang, RBF Neural Networks for the Prediction of Building\n",
            "Interference effects, Computers and Structures, Vol. 82, No. 27(2004) 2333\n",
            "-2339\n",
            "[6] Brown.S. Aaron, T.Y. Henry, Yang, Neural Networks for multi Objective\n",
            "Adaptive Structural Control, Structural Engineering ASCE, Vol.127, No.2,\n",
            "(2001) 203-\n",
            "[7] C.S. Huang, S.L. Hung, C.M. Wen, T.T.Tu, A Neural Network Approach for\n",
            "Structural Identification and Diagnosis of a Building from Seismic Response\n",
            "Data, Earthquake Engineering and Structural Dynamics, Vol. 32, No. 2,\n",
            "(2003) 187-\n",
            "[8] C.Y. Kao, Shin Lin Hung, Detection of structural Damage via Free Vibration\n",
            "Responses generated by Approximating Artificial Neural Network,\n",
            "Computers and Structures,Vol.81,No. 28-29 (2003), 2631-2644\n",
            "[9] D.A. Liut, E.E Matheu, M.P. Singh, D.T. Mook, Neural Network Control of\n",
            "building Structures by a Force Matching Training Scheme, Earthquake\n",
            "Engineering and Structural Dynamics, Vol. 28, No. 12 (1999) 1601-\n",
            "[10] J .Zhao, J.N. Ivan, J.T. DeWolf, Structural damage detection using artificial\n",
            "neural networks. Journal of Infrastructure Systems (ASCE) Vol.4, No.(3)\n",
            "(1998) 93 – 101.\n",
            "[11] Krystyna KuZniar, Zenon Waszczyszyn, Neural Simulation of Dynamic\n",
            "Response of Prefabricated Buildings Subjected to Paraseismic Excitations,\n",
            "Computers and Structures,Vol. 81, No. 24-25 (2003) 2353-2360\n",
            "[12] M.F. Elkordy, K.C. Chang, G.C. Lee, Neural networks trained by analytically\n",
            "simulated damage states. Journal of Computing in Civil Engineering (ASCE)\n",
            "Vol. 7, No.2 (1993) 130 – 145.\n",
            "[13] N.S. Hadi Muhammad, Neural Networks Applications in Concrete\n",
            "Structures, Computers and Structures, Vol.81, No. 6 (2003) 373-381\n",
            "[14] P.C. Pandey, S.V. Barai, Multilayer perceptron in damage detection of\n",
            "bridge structures. Computers and Structures Vol. 54, No.4 (1995) 597- 608.\n",
            "[15] Q. Chen, Y.W. Chan, K. Worden, Structural Fault Diagnosis and Isolation\n",
            "using Neural Network Based on Response Only Data, Vol. 81, No. 22-23\n",
            "(2003) 2165 -2172\n",
            "[16] S.F. Masri, A.W. Smyth, A.G. Chassiakos, T.K. Caughey, N.F. Hunter,\n",
            "Application of Neural networks for detection of changes in nonlinear\n",
            "systems. Journal of Engineering Mechanics (ASCE), Vol. 126, No.70 (2000)\n",
            "666 – 676.\n",
            "[17] S.L. Hung, C.Y. Kao, Structural Damage Detection Using the Optimal\n",
            "Weights of the Approximating Artificial Neural Networks, Earthquake\n",
            "Engineering and Structural Dynamics,Vol. 31, No.2, (2002) 217-\n",
            "[18] V.K. Mathur, S. Chakraverty and Pallavi Gupta, Response Prediction of\n",
            "Typical Rural House Subject to Earthquake Motions Using Artificial Neural\n",
            "Networks. Journal of Indian Building Congress, Vol.11, No.2 (2004) 99-105.\n",
            "20\n",
            "15\n",
            "10\n",
            "5\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-5\n",
            "-10\n",
            "-15\n",
            "Time\n",
            "Fig. 2(a). Chamoli Earthquake at Barkot in NE direction\n",
            "Peak Acceleration = 0.16885m/sec/sec\n",
            "Fig. 2(b) Uttarkashi Earthquake at Barkot in NE direction\n",
            "Peak Acceleration : 0.9317m/sec/sec\n",
            "Fig. 2(c). Uttarkashi Earthquake at Barkot in NW direction\n",
            "Peak Acceleration : 0.8470m/sec/sec\n",
            "noitareleccA\n",
            "1.2\n",
            "1\n",
            "0.8\n",
            "0.6\n",
            "0.4\n",
            "0.2\n",
            "0\n",
            "-0.2 0 5 10 15 20 25 30 35\n",
            "-0.4\n",
            "-0.6\n",
            "-0.8\n",
            "-1\n",
            "Time\n",
            "noitareleccA\n",
            "1\n",
            "0.8\n",
            "0.6\n",
            "0.4\n",
            "0.2\n",
            "0\n",
            "-0.2 0 5 10 15 20 25 30 35\n",
            "-0.4\n",
            "-0.6\n",
            "-0.8\n",
            "-1\n",
            "Time\n",
            "noitareleccA\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.05\n",
            "-0.1\n",
            "Time\n",
            "Fig. 3(a). 80% Response comparison Between Neural and Desired of Chamoli\n",
            "Earthquake at Barkot (NE) for ωωωω=0.01\n",
            "Fig. 3(b). 120% Response comparison Between Neural and Desired of Chamoli\n",
            "Earthquake at Barkot (NE) for ωωωω=0.5\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.25\n",
            "0.2\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.05\n",
            "-0.1\n",
            "-0.15\n",
            "Time\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.2\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12\n",
            "-0.05\n",
            "-0.1\n",
            "-0.15\n",
            "Time\n",
            "Fig. 4(a). Response Comparison Between Neural and Desired (550 points)\n",
            "of Chamoli Earthquake at Barkot (NE) for ωωωω=0.01\n",
            "Fig. 4(b). Response Comparison Between Neural and Desired (550 points)\n",
            "of Chamoli Earthquake at Barkot (NE) for ωωωω=0.5\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.2\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12\n",
            "-0.05\n",
            "-0.1\n",
            "-0.15\n",
            "Time\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.25\n",
            "0.2\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.05\n",
            "-0.1\n",
            "-0.15\n",
            "Time\n",
            "Fig. 5(a). 120% Response Comparison Between Neural and Desired\n",
            "of Chamoli Earthquake at Barkot (NE) (748 points) ωωωω=0.01\n",
            "(After training from 550 points)\n",
            "Fig. 5(b). 80% Response Comparison Between Neural and Desired\n",
            "of Chamoli Earthquake at Barkot (NE) (748 points) ωωωω=0.5\n",
            "(After training from 550 points)\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.15\n",
            "0.1\n",
            "0.05\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.05\n",
            "-0.1\n",
            "Time\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.01\n",
            "0.008\n",
            "0.006\n",
            "0.004\n",
            "0.002\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.002\n",
            "-0.004\n",
            "-0.006\n",
            "Time\n",
            "Fig.6(a). 100% Response Comparison Between Neural and Desired of Chamoli\n",
            "Earthquake at Barkot (NE)with Damping\n",
            "Fig.6(b). 50% Response Comparison Between Neural and Desired of Chamoli\n",
            "Earthquake at Barkot (NE) with Damping\n",
            "Fig.6(c). 120% Response Comparison Between Neural and Desired of Chamoli\n",
            "Earthquake at Barkot (NE) with Damping\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.005\n",
            "0.004\n",
            "0.003\n",
            "0.002\n",
            "0.001\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.001\n",
            "-0.002\n",
            "-0.003\n",
            "Time\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.01\n",
            "0.008\n",
            "0.006\n",
            "0.004\n",
            "0.002\n",
            "0\n",
            "0 2 4 6 8 10 12 14 16\n",
            "-0.002\n",
            "-0.004\n",
            "-0.006\n",
            "-0.008\n",
            "Time\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.007\n",
            "0.006\n",
            "0.005\n",
            "0.004\n",
            "0.003\n",
            "0.002\n",
            "0.001\n",
            "0\n",
            "0 2 4 6 8 10 12\n",
            "Time Period\n",
            "Fig. 7(a). Comparison Between Neural and Desired for time period and the\n",
            "corresponding maximum response of Uttarkashi earthquake at\n",
            "Barkot in NW direction ( 620 points )\n",
            "Fig. 7(b). Comparison Between Neural and Desired for time period and the\n",
            "corresponding maximum response of Uttarkashi earthquake at\n",
            "Tehri in NW direction ( From weights of 620 points )\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "0.007\n",
            "0.006\n",
            "0.005\n",
            "0.004\n",
            "0.003\n",
            "0.002\n",
            "0.001\n",
            "0\n",
            "0 2 4 6 8 10 12\n",
            "Time period\n",
            "noitareleccA\n",
            "Neural Desired\n",
            "\n",
            "Q: What is the error backpropagation training algorithm (EBPTA), and how is it used in this study?\n",
            "\n",
            "A: The Error Back Propagation Training Algorithm (EBPTA) is a method used in training artificial neural networks. In this study, it is used to adjust the weights in the network. The weights are the strengths of the connections between the neurons in the network, and adjusting them changes the input/output behavior of the network.\n",
            "\n",
            "The process works as follows:\n",
            "\n",
            "1. The algorithm is given a set of training pairs, which include inputs and desired outputs.\n",
            "2. The algorithm computes an error value for the present neural network.\n",
            "3. The error signal terms of the output and hidden layers are calculated.\n",
            "4. The weights of the output layer and hidden layer are adjusted based on these error signal terms and a learning constant.\n",
            "\n",
            "In the context of this research paper on predicting structural system responses to earthquakes, the EBPTA is used to train the neural network on ground acceleration and response data from earthquakes. Once trained, the network can be used to simulate responses for earthquakes of various intensities.\n",
            "\n",
            "Q: What did the response predictions show for varying earthquake intensities after training with the Chamoli earthquake data?\n",
            "\n",
            "A: After training with the Chamoli earthquake data, the Artificial Neural Network (ANN) model was able to predict responses for earthquakes of various intensities. The trained model was tested for 80% and 120% of the Chamoli earthquake's intensity. The results showed a good match between the predicted responses and the actual responses.\n",
            "\n",
            "For instance, when tested with 80% of the Chamoli earthquake at Barkot (NE) for a frequency parameter ω=0.01, the maximum response was 0.135079 m/sec/sec. Similarly, for 120% of the Chamoli earthquake at Barkot (NE) for ω=0.5, the maximum response was 0.20260 m/sec/sec. These results suggest that the ANN model can accurately predict the responses of structural systems to earthquakes of various intensities. \n",
            "\n",
            "The model also showed its ability to predict responses to earthquakes not used in the training phase. This means that it can potentially predict the safety of structural systems in case of future earthquakes.\n",
            "\n",
            "Q: Which parameters define the natural frequency of a structure, as per the document?\n",
            "\n",
            "A: The natural frequency of a structure, denoted as ω² in the document, is determined by two key parameters: the stiffness of the structure, represented as K, and the mass of the structure, represented as M. The natural frequency parameter is calculated as ω² = K/M. \n",
            "\n",
            "This natural frequency is significant because if the ground shakes with the same frequency as a building's natural frequency, it can cause the building to sway with increasing amplitude, placing the most strain on the components of the building and potentially leading to collapse. This is why understanding and predicting the natural frequency of a building is crucial in earthquake-prone areas.\n",
            "\n",
            "Q: How many hidden layer nodes were found to be optimal for the ANN model's hidden layer?\n",
            "\n",
            "A: The researchers found that using between 5 to 20 nodes in the hidden layer of the Artificial Neural Network (ANN) model produced almost the same good results. However, for the sake of generating further results, they decided to use 10 nodes in the hidden layer. This was found to be sufficient for accurate prediction of the structural responses to various intensity earthquakes.\n",
            "\n",
            "Q: Which data set was used to validate the ANN model's predictions for time periods and maximum responses?\n",
            "\n",
            "A: The Uttarkashi earthquake at Tehri in NW direction was used to validate the ANN model's predictions for time periods and maximum responses. This data set was not used during the training phase. The ANN model, which was trained with the time periods and corresponding maximum responses from the Uttarkashi earthquake at Barkot in NW direction, was able to predict the maximum response directly to the corresponding time period for the Tehri earthquake. The results showed good agreement between the model's predictions and the actual data.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}