{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 7\n",
        "\n",
        "### Poojitha Venkatram\n",
        "\n",
        "#### https://github.com/poojithavenkatram/Deep-Learning"
      ],
      "metadata": {
        "id": "6uVGX3uRpX2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52vN1d_hpeUT",
        "outputId": "cf6ff13e-7df1-4d48-e4e1-6b5310d2efe5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Wikipedia GLoVE Word2Vec"
      ],
      "metadata": {
        "id": "0Ad8wlZQuwok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvPT5rHbt9O3",
        "outputId": "441baa35-73bd-498d-fc87-30ed472db787"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2zaYFdcwIFb",
        "outputId": "c9234fc9-d6ff-4bff-cd7f-692391990855"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 05:01:23--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-03-28 05:01:23--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-03-28 05:01:23--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 38s  \n",
            "\n",
            "2024-03-28 05:04:02 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove/glove.6B.50d.txt  \n",
            "  inflating: glove/glove.6B.100d.txt  \n",
            "  inflating: glove/glove.6B.200d.txt  \n",
            "  inflating: glove/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_input_file = 'glove/glove.6B.50d.txt'  # Path to the GLoVE file\n",
        "word2vec_output_file = 'glove/glove.6B.50d.txt.word2vec'  # Output file\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2FHORTFvMsx",
        "outputId": "d78e2aa5-e6c8-4bc7-994e-670b729326fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-620fd7923d13>:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# Load the converted model\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "metadata": {
        "id": "byqpsPGuxzz7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show how similar are these words"
      ],
      "metadata": {
        "id": "tS_R8iAbw50j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity between different pairs of words\n",
        "words_pairs = [('man', 'woman'), ('chair', 'throne'), ('water', 'baby')]\n",
        "for word1, word2 in words_pairs:\n",
        "    print(f\"Similarity between {word1} and {word2}: {model.similarity(word1, word2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZoWQ7tFwSeG",
        "outputId": "2518bfb0-dcc4-4c06-cb2f-caa819da8995"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between man and woman: 0.8860337734222412\n",
            "Similarity between chair and throne: 0.27968090772628784\n",
            "Similarity between water and baby: 0.40810367465019226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using these provide analogies for the following"
      ],
      "metadata": {
        "id": "_OYFk3T1xnMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the analogy tasks\n",
        "analogy_tasks = [\n",
        "    ('king', 'man', 'woman'),\n",
        "    ('princess', 'woman', 'man'),\n",
        "    ('adult', 'child', 'woman')\n",
        "]\n",
        "\n",
        "# Solve each analogy\n",
        "for word1, word2, word3 in analogy_tasks:\n",
        "    try:\n",
        "        # Predict the most similar word\n",
        "        predicted = model.most_similar(positive=[word1, word3], negative=[word2], topn=1)\n",
        "        print(f\"{predicted[0][0]} is to {word1} as {word3} is to {word2}.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}. One of the words in the analogy '{word1}', '{word2}', or '{word3}' is not in the model's vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Z1YcGuxmFJ",
        "outputId": "0d78c8a2-1bdb-453d-eca6-8f7ff13eed60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen is to king as woman is to man.\n",
            "prince is to princess as man is to woman.\n",
            "male is to adult as woman is to child.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Naive-Bayes Classifier on the Spam-Ham dataset shown in the demo."
      ],
      "metadata": {
        "id": "-5Z9VnBT0l68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Loading the file\n",
        "file_path = '/content/drive/MyDrive/spam.csv'\n",
        "df = pd.read_csv(file_path, encoding='latin1')\n",
        "\n",
        "# Display column names and the first few rows of the DataFrame\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "# Preprocessing Step 1: Removing punctuations\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "# Preprocessing Step 2: Converting text to lowercase\n",
        "df['v2'] = df['v2'].apply(lambda x: x.lower())\n",
        "\n",
        "# Updating the 'label' column\n",
        "df['v1'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHIRsjE3tQRz",
        "outputId": "6b8aea3b-4095-4999-ab26-e8e1c56829cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "   v1                                                 v2 Unnamed: 2  \\\n",
            "0   0  go until jurong point, crazy.. available only ...        NaN   \n",
            "1   0                      ok lar... joking wif u oni...        NaN   \n",
            "2   1  free entry in 2 a wkly comp to win fa cup fina...        NaN   \n",
            "3   0  u dun say so early hor... u c already then say...        NaN   \n",
            "4   0  nah i don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/spam.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Preprocess the data\n",
        "# For simplicity, we'll only keep the 'v1' (label) and 'v2' (message) columns\n",
        "df = df[['v1', 'v2']]\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Convert labels to numerical format\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text messages\n",
        "vectorizer = CountVectorizer(stop_words='english', lowercase=True)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = nb_classifier.predict(X_train_vectorized)\n",
        "y_pred_test = nb_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "classification_report_test = classification_report(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix_test)\n",
        "print(\"Classification Report:\\n\", classification_report_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqyEk30z6j0l",
        "outputId": "7f175f36-b35b-4f7a-c80e-84d4d4bd7db7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9946152120260264\n",
            "Test Accuracy: 0.9838565022421525\n",
            "Confusion Matrix:\n",
            " [[959   6]\n",
            " [ 12 138]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       965\n",
            "           1       0.96      0.92      0.94       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.97      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}