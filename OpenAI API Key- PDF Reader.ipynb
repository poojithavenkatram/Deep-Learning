{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Open API Overview\n",
        "#### Poojitha Venkatram\n",
        "##### Github Link- https://github.com/poojithavenkatram/Deep-Learning"
      ],
      "metadata": {
        "id": "4mRq6e3WQGv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "G233lSCzQJ82",
        "outputId": "9acb508b-b56b-45c8-cd2d-c9b41f9f8d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.23.6\n",
            "    Uninstalling openai-1.23.6:\n",
            "      Successfully uninstalled openai-1.23.6\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "1467fdc0810545b98a1f73047adaac24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "s-VETvmcQgPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \" OpenAI API Key \""
      ],
      "metadata": {
        "id": "YrUOOmGNQlXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install openai --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB696yAwQ5bS",
        "outputId": "4256c145-6f8b-487a-8f5c-9b7717e71d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! openai migrate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97L8wPh2RY1w",
        "outputId": "be2422e9-bcec-42be-e4c0-47c8a72e3561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving Grit CLI metadata from https://api.keygen.sh/v1/accounts/custodian-dev/artifacts/marzano-linux-x64\n",
            "Fetching release URL from: https://api.keygen.sh//v1/accounts/custodian-dev/artifacts/marzano-linux-x64\n",
            "Fetching release URL from: https://api.keygen.sh//v1/accounts/custodian-dev/artifacts/gouda-linux-x64\n",
            "Fetching release URL from: https://api.keygen.sh//v1/accounts/custodian-dev/artifacts/cli-linux-x64\n",
            "Fetching release URL from: https://api.keygen.sh//v1/accounts/custodian-dev/artifacts/workflow_runner-linux-x64\n",
            "Fetching release URL from: https://api.keygen.sh//v1/accounts/custodian-dev/artifacts/timekeeper-linux-x64\n",
            "\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2mFinding files                                                         \u001b[0m\n",
            "\u001b[2K\u001b[2AProcessed 0 files and found 0 matches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Ask the bot to solve one complex math problem."
      ],
      "metadata": {
        "id": "LaL_bA2S5RVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def ask_gpt():\n",
        "    model_choice = \"gpt-3.5-turbo-16k\"\n",
        "    # Prompt\n",
        "    insert_prompt = \"I have a math problem that needs solving. Can you help me calculate the integral of (3x^2 - 2x + 1) dx from x = 0 to x = 5?\"\n",
        "\n",
        "    try:\n",
        "        # Make an API call to OpenAI\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model_choice,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": insert_prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Usage\n",
        "print(ask_gpt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMLMfffQQtDD",
        "outputId": "b2467ee5-7ae6-473d-b7aa-6db411da0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course! To calculate the integral of the function (3x^2 - 2x + 1) dx from x = 0 to x = 5, we can use the power rule for integration.\n",
            "\n",
            "The power rule states that the integral of x^n dx, where n is a constant (n ≠ -1), is (1/(n+1)) * x^(n+1) + C, where C is the constant of integration.\n",
            "\n",
            "Applying the power rule to each term of the function separately, we get:\n",
            "\n",
            "∫(3x^2 - 2x + 1) dx = (1/3) * x^3 - (1/2) * x^2 + x + C\n",
            "\n",
            "Now, we can evaluate this expression at the upper and lower limits of integration:\n",
            "\n",
            "∫(3x^2 - 2x + 1) dx evaluated from x = 0 to x = 5:\n",
            "= [(1/3) * 5^3 - (1/2) * 5^2 + 5] - [(1/3) * 0^3 - (1/2) * 0^2 + 0]\n",
            "= [(1/3) * 125 - (1/2) * 25 + 5] - 0\n",
            "= (125/3 - 25/2 + 5)\n",
            "= (375/3 - 75/6 + 30/6)\n",
            "= (375 - 75 + 30) / 6\n",
            "= 330 / 6\n",
            "= 55\n",
            "\n",
            "Therefore, the integral of (3x^2 - 2x + 1) dx from x = 0 to x = 5 is equal to 55.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v16m1OBQXUdm",
        "outputId": "4c083de3-ba4a-41d1-89e4-1f1243fcc093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Give a PDF and website document; ask the bot to rewrite and answer questions on the given PDF and website."
      ],
      "metadata": {
        "id": "UF5JjSGT5fB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def process_document(document_type, content, task, question=None):\n",
        "    model_choice = \"gpt-3.5-turbo-16k\"\n",
        "    if document_type not in ['pdf', 'website']:\n",
        "        return \"Invalid document type. Please specify 'pdf' or 'website'.\"\n",
        "\n",
        "    system_message = \"You are a helpful assistant capable of processing documents.\"\n",
        "    if document_type == 'pdf':\n",
        "        user_message = f\"Please process this PDF and {task}: {content}\"\n",
        "    elif document_type == 'website':\n",
        "        user_message = f\"Please process this website and {task}: {content}\"\n",
        "\n",
        "    if question:\n",
        "        user_message += f\" Also, answer this question: {question}\"\n",
        "\n",
        "    try:\n",
        "        # Make an API call to OpenAI\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model_choice,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Requesting the AI to rewrite content from a PDF and answer a question\n",
        "print(process_document('pdf', '/content/drive/MyDrive/extracted_arxiv_papers/0704_1394_extracted.pdf', 'rewrite', 'What is the abstract of the document?'))\n",
        "\n",
        "# Requesting the AI to answer a question based on website content\n",
        "print(process_document('website', 'https://www.t-mobile.com/', 'answer questions', 'How can I contact customer support?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxE6A461WjD0",
        "outputId": "2d17fe45-8e5b-4e37-9e2e-ec4fcd1f4069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but as a text-based AI language model, I am unable to directly process PDF files or access external files from Google Drive. However, if you provide the text content of the PDF, I would be more than happy to assist you with rewriting and answering any questions based on the provided text.\n",
            "\n",
            "Please copy and paste the text from the PDF, and I'll be glad to help you with your request.\n",
            "I apologize, but as a text-based assistant, I am unable to directly process websites. However, I can provide you with the information you need.\n",
            "\n",
            "To contact T-Mobile customer support, you have several options:\n",
            "\n",
            "1. Phone: You can dial 611 from your T-Mobile phone or call 1-800-937-8997 to reach customer support representatives.\n",
            "\n",
            "2. T-Mobile App: You can use the T-Mobile app on your smartphone or tablet to chat with a representative.\n",
            "\n",
            "3. Online Chat: Visit the T-Mobile website and navigate to the \"Contact Us\" section. From there, you can initiate a chat with a customer support agent.\n",
            "\n",
            "4. Social Media: T-Mobile has dedicated support accounts on platforms like Facebook, Twitter, and Instagram. You can reach out to them through these channels as well.\n",
            "\n",
            "Remember to provide relevant details about your query or issue when reaching out to customer support to ensure a prompt and accurate response.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Summarize a text from the PDF"
      ],
      "metadata": {
        "id": "KJZmIFl_5uw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "def ask_gpt_to_summarize(text):\n",
        "    model_choice = \"gpt-3.5-turbo-16k\"\n",
        "    task = \"summarize the following text in three sentences:\"\n",
        "\n",
        "    try:\n",
        "        # Make an API call to OpenAI\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model_choice,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant capable of summarizing texts.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{task} {text}\"}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Text to Summarize\n",
        "text_description = \"\"\"\n",
        "Interactive configuration problems are special applications of Constraint Satisfaction Problems (CSP) where a user is assisted in interactively assigning values to variables by a software tool. This software, called a configurator, assists the user by calculating and displaying the available, valid choices for each unassigned variable in what are called valid domains computations. Application areas include customising physical products (such as PC’s and cars) and services (such as airplane tickets and insurances). Three important features are required of a tool that implements interactive configuration: it should be complete (all valid configurations should be reachable through user interaction), backtrack-free (a user is never forced to change an earlier choice due to incompleteness in the logical deductions), and it should provide real-time performance (feedback should be fast enough to allow real-time interactions). The requirement of obtaining backtrack-freeness while maintaining completeness makes the problem of calculating valid domains NP-hard. The real-time performance requirement enforces further that runtime calculations are bounded in polynomial time. According to user-interface design criteria, for a user to perceive interaction as being real-time, system response needs to be within about 250 milliseconds in practice [2]. Therefore, the current approaches that meet all three conditions use off-line precomputation to generate an efficient runtime data structure representing the solution space [3,4,5,6]. The challenge with this data structure is that the solution space is almost always exponentially large and it is NP-hard to find. Despite the bad worst-case bounds, it has nevertheless turned out in real industrial applications that the data structures can often be kept small [7,5,4].\n",
        "\"\"\"\n",
        "\n",
        "# Usage\n",
        "print(ask_gpt_to_summarize(text_description))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R758fKRX4iu",
        "outputId": "e66025f0-e3ed-4cbe-c114-832d7699ed88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive configuration problems involve assisting users in assigning values to variables using a software tool. These problems arise in various application areas such as customizing products and services. To meet the requirements of completeness, backtrack-freeness, and real-time performance, current approaches use off-line precomputation to generate an efficient data structure representing the solution space, despite its exponential size and NP-hardness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Display this in a DF\n",
        "ask_gpt_to_summarize(text_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "PNGUpSLqYobF",
        "outputId": "0a78a374-480d-413b-8099-b7eb31118ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Interactive configuration problems are special applications of Constraint Satisfaction Problems (CSP) where a software tool assists users in assigning values to variables. The tool calculates and displays valid choices for each variable, known as valid domains computations. To meet the requirements of completeness, backtrack-freeness, and real-time performance, current approaches use offline precomputation to generate an efficient runtime data structure. Although the solution space can be exponentially large and NP-hard to find, the data structures can often be kept small in real industrial applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Ask the bot to summarize your chat."
      ],
      "metadata": {
        "id": "iAcVwQ_058yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def ask_gpt_to_summarize_chat(chat_history):\n",
        "    model_choice = \"gpt-3.5-turbo-16k\"\n",
        "    task = \"summarize the following chat interactions in three sentences:\"\n",
        "\n",
        "    try:\n",
        "        # Make an API call to OpenAI\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model_choice,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant capable of summarizing chat interactions.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{task} {chat_history}\"}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Usage\n",
        "print(ask_gpt_to_summarize_chat(chat_history))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYdppCnbYvwM",
        "outputId": "7cfced3d-5663-49d1-c14d-fdc8ed7376be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The user needed assistance with a Python function for interacting with an API to solve math problems and handle documents.\n",
            "2. The user asked about mounting Google Drive in a Google Colab notebook and received step-by-step instructions.\n",
            "3. The user needed help configuring a summary request for a detailed explanation of interactive configuration problems and the difficulties associated with them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Display in a DF\n",
        "ask_gpt_to_summarize_chat(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fkZtUOlbZF4b",
        "outputId": "61913545-a51a-4178-fd4d-3e5a200c05ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the first chat interaction, the user asked for assistance with a Python function to interact with an API for solving math problems and managing documents.\\nIn the second interaction, the user sought guidance on how to mount Google Drive in a Google Colab notebook and was provided with detailed instructions.\\nLastly, the user requested help in configuring a summary request for a comprehensive description of configuration problems and their computational challenges.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}