{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Assignment - Part 1\n",
        "## Wide and Deep Recomendation System\n",
        "### Shruti Badrinarayanan, Poojitha Venkatram"
      ],
      "metadata": {
        "id": "hRhrOe29fZQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYwixxbNjKWs",
        "outputId": "a6aca771-d928-456b-a900-2da005184d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUXbBFYkJUWV"
      },
      "outputs": [],
      "source": [
        "# pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGTPxELcJUWV"
      },
      "outputs": [],
      "source": [
        "# pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "U3fkrbnsho-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcDX5Em3jMPO",
        "outputId": "9bc2a138-01d8-4aed-e4d0-f5bde6642faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-ba258d49bd75>:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  books = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Books.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
            "Skipping line 6452: expected 8 fields, saw 9\n",
            "Skipping line 43667: expected 8 fields, saw 10\n",
            "Skipping line 51751: expected 8 fields, saw 9\n",
            "\n",
            "Skipping line 92038: expected 8 fields, saw 9\n",
            "Skipping line 104319: expected 8 fields, saw 9\n",
            "Skipping line 121768: expected 8 fields, saw 9\n",
            "\n",
            "Skipping line 144058: expected 8 fields, saw 9\n",
            "Skipping line 150789: expected 8 fields, saw 9\n",
            "Skipping line 157128: expected 8 fields, saw 9\n",
            "Skipping line 180189: expected 8 fields, saw 9\n",
            "Skipping line 185738: expected 8 fields, saw 9\n",
            "\n",
            "Skipping line 209388: expected 8 fields, saw 9\n",
            "Skipping line 220626: expected 8 fields, saw 9\n",
            "Skipping line 227933: expected 8 fields, saw 11\n",
            "Skipping line 228957: expected 8 fields, saw 10\n",
            "Skipping line 245933: expected 8 fields, saw 9\n",
            "Skipping line 251296: expected 8 fields, saw 9\n",
            "Skipping line 259941: expected 8 fields, saw 9\n",
            "Skipping line 261529: expected 8 fields, saw 9\n",
            "\n",
            "<ipython-input-68-ba258d49bd75>:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Books.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
            "<ipython-input-68-ba258d49bd75>:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  users = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Users.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
            "<ipython-input-68-ba258d49bd75>:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  ratings = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Book-Ratings.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(         ISBN                                         Book-Title  \\\n",
              " 0  0195153448                                Classical Mythology   \n",
              " 1  0002005018                                       Clara Callan   \n",
              " 2  0060973129                               Decision in Normandy   \n",
              " 3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
              " 4  0393045218                             The Mummies of Urumchi   \n",
              " \n",
              "             Book-Author Year-Of-Publication                   Publisher  \\\n",
              " 0    Mark P. O. Morford                2002     Oxford University Press   \n",
              " 1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
              " 2          Carlo D'Este                1991             HarperPerennial   \n",
              " 3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
              " 4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
              " \n",
              "                                          Image-URL-S  \\\n",
              " 0  http://images.amazon.com/images/P/0195153448.0...   \n",
              " 1  http://images.amazon.com/images/P/0002005018.0...   \n",
              " 2  http://images.amazon.com/images/P/0060973129.0...   \n",
              " 3  http://images.amazon.com/images/P/0374157065.0...   \n",
              " 4  http://images.amazon.com/images/P/0393045218.0...   \n",
              " \n",
              "                                          Image-URL-M  \\\n",
              " 0  http://images.amazon.com/images/P/0195153448.0...   \n",
              " 1  http://images.amazon.com/images/P/0002005018.0...   \n",
              " 2  http://images.amazon.com/images/P/0060973129.0...   \n",
              " 3  http://images.amazon.com/images/P/0374157065.0...   \n",
              " 4  http://images.amazon.com/images/P/0393045218.0...   \n",
              " \n",
              "                                          Image-URL-L  \n",
              " 0  http://images.amazon.com/images/P/0195153448.0...  \n",
              " 1  http://images.amazon.com/images/P/0002005018.0...  \n",
              " 2  http://images.amazon.com/images/P/0060973129.0...  \n",
              " 3  http://images.amazon.com/images/P/0374157065.0...  \n",
              " 4  http://images.amazon.com/images/P/0393045218.0...  ,\n",
              "    User-ID                            Location   Age\n",
              " 0        1                  nyc, new york, usa   NaN\n",
              " 1        2           stockton, california, usa  18.0\n",
              " 2        3     moscow, yukon territory, russia   NaN\n",
              " 3        4           porto, v.n.gaia, portugal  17.0\n",
              " 4        5  farnborough, hants, united kingdom   NaN,\n",
              "    User-ID        ISBN  Book-Rating\n",
              " 0   276725  034545104X            0\n",
              " 1   276726  0155061224            5\n",
              " 2   276727  0446520802            0\n",
              " 3   276729  052165615X            3\n",
              " 4   276729  0521795028            6)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the datasets\n",
        "books = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Books.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
        "users = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Users.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/Lab/Part 1/BX-Book-Ratings.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')\n",
        "\n",
        "# Display the first few rows of each dataset to understand its structure\n",
        "books.head(), users.head(), ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "1fAutYtlhr7-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFyMDe4Z0FTM"
      },
      "outputs": [],
      "source": [
        "ratings_and_books = ratings.merge(books, on='ISBN', how='inner', suffixes=('_1', '_2'))\n",
        "all = ratings_and_books.merge(users, on='User-ID', how='inner', suffixes=('_1', '_2'))\n",
        "all_copy = all.copy()\n",
        "all.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'User-ID', 'ISBN'], axis=1, inplace=True)\n",
        "\n",
        "# Assuming books, users, and ratings have been filtered to only include relevant rows\n",
        "# Fill NaN values with a placeholder\n",
        "all['Book-Title'] = all['Book-Title'].fillna('Unknown')\n",
        "all['Book-Author'] = all['Book-Author'].fillna('Unknown')\n",
        "all['Age'] = all['Age'].fillna(int(all['Age'].mean())).values\n",
        "\n",
        "all[\"Age\"] = pd.to_numeric(all[\"Age\"])\n",
        "\n",
        "all.drop(all.loc[all['Year-Of-Publication']=='DK Publishing Inc'].index, inplace=True)\n",
        "all.drop(all.loc[all['Year-Of-Publication']=='Gallimard'].index, inplace=True)\n",
        "\n",
        "all[\"Year-Of-Publication\"] = pd.to_numeric(all[\"Year-Of-Publication\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPdLT4iFPv0z",
        "outputId": "3bf0b322-aa17-4095-ff67-fe0aed2c103e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Book-Rating              int64\n",
              "Book-Title              object\n",
              "Book-Author             object\n",
              "Year-Of-Publication      int64\n",
              "Publisher               object\n",
              "Location                object\n",
              "Age                    float32\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "all['Age'] = all['Age'].astype('float32')\n",
        "\n",
        "all.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkG8w3swS2Li"
      },
      "outputs": [],
      "source": [
        "# all_sample = all.sample(n=100000)\n",
        "all_sample = all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_sample"
      ],
      "metadata": {
        "id": "xcFdGAf7TVt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define BookDataset Class which helps initialise the Data"
      ],
      "metadata": {
        "id": "GcczVRwBhyv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nj36jMjCP6p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class BookDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.df = dataframe\n",
        "\n",
        "        # Preprocess string features with categorical embeddings\n",
        "        self.embedders = {}\n",
        "        for col in ['Book-Title', 'Book-Author', 'Publisher', 'Location']:\n",
        "            encoder = LabelEncoder()\n",
        "            self.df[col] = encoder.fit_transform(self.df[col])\n",
        "            self.embedders[col] = (encoder.classes_.size, min(10, len(encoder.classes_)//2)) # Adjust embedding size as needed\n",
        "\n",
        "        # Target variable\n",
        "        self.target = self.df['Book-Rating'].to_numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = {\n",
        "            col: torch.tensor(self.df[col].iloc[index]).long()\n",
        "            for col in ['Book-Title', 'Book-Author', 'Publisher', 'Location', 'Year-Of-Publication', 'Age']\n",
        "        }\n",
        "\n",
        "        return features, torch.nn.functional.one_hot(torch.tensor(self.target[index]), 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4YIcGMdA9LJ"
      },
      "outputs": [],
      "source": [
        "train_df = all_sample.sample(frac=0.8, random_state=42)\n",
        "test_df = all_sample.drop(train_df.index)\n",
        "\n",
        "train_df_copy = train_df.copy()\n",
        "test_df_copy = test_df.copy()\n",
        "\n",
        "train_dataset = BookDataset(train_df_copy)\n",
        "test_dataset = BookDataset(test_df_copy)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model"
      ],
      "metadata": {
        "id": "GqUH3NtYh6nU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86aF-6c0j6Oq"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BookRatingModel(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dims = embedding_dims\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            name: nn.Embedding(num_embeddings, dim)\n",
        "            for name, (num_embeddings, dim) in embedding_dims.items()\n",
        "        })\n",
        "\n",
        "        # Dense layers for continuous features and embeddings\n",
        "        self.deep_layers = nn.Sequential(\n",
        "            nn.Linear(42, 128),  # Adjust sizes as needed\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 11)\n",
        "        )\n",
        "\n",
        "        self.wide_layer = nn.Linear(42, 11)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = [self.embeddings[name](x[name]) for name in ['Book-Title', 'Book-Author', 'Publisher', 'Location']]\n",
        "        embeddings = torch.cat(embeddings, dim=1)\n",
        "        x = torch.cat([embeddings, x['Year-Of-Publication'].unsqueeze(1), x['Age'].unsqueeze(1)], dim=1)\n",
        "        return self.deep_layers(x) + self.wide_layer(x)\n",
        "\n",
        "# Initialize the model\n",
        "embedding_dims = train_dataset.embedders  # Get embedding dimensions from the dataset\n",
        "model = BookRatingModel(embedding_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWkjBRCLh0cE"
      },
      "outputs": [],
      "source": [
        "def eval():\n",
        "  # Evaluate the model\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          features, targets = data\n",
        "          outputs = model(features)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "          for i, target in enumerate(targets):\n",
        "            one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n",
        "            correct += torch.all(torch.eq(targets[i], one_hot[i])).item()\n",
        "          total += targets.size(0)\n",
        "  print(f'Accuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "VSIka4XNiBMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SshlTLVQo2Ah",
        "outputId": "1108aae1-4f4d-44e2-973b-05b74a57be47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 1.9596067667007446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_184/1175092157.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 49.207%\n",
            "Epoch 2, Average Loss: 1.667163372039795\n",
            "Accuracy on test set: 57.359%\n",
            "Epoch 3, Average Loss: 1.6333808898925781\n",
            "Accuracy on test set: 42.978%\n",
            "Epoch 4, Average Loss: 1.6002947092056274\n",
            "Accuracy on test set: 20.536%\n",
            "Epoch 5, Average Loss: 1.5620392560958862\n",
            "Accuracy on test set: 54.305%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "loss_fn = nn.CrossEntropyLoss()  # Cross Entropy loss\n",
        "\n",
        "for epoch in range(5):\n",
        "    i = 0\n",
        "    cum_loss = 0\n",
        "    total_batches = len(train_loader)\n",
        "    for features, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = loss_fn(outputs.squeeze(), targets.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        cum_loss += loss\n",
        "        # if i > 0 and i % 500 == 0:\n",
        "        #   print('Loss=', loss.item(), 'in', i, '/', total_batches, 'batches', 'in epoch', epoch)\n",
        "    avg_loss = cum_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss}\")\n",
        "    eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZuPX48_YJA2",
        "outputId": "0353da6b-64f2-4f3f-ad53-8f5158b45102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_184/22237457.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on train set: 64.772%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        features, targets = data\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for i, target in enumerate(targets):\n",
        "          one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n",
        "          correct += torch.all(torch.eq(targets[i], one_hot[i])).item()\n",
        "        total += targets.size(0)\n",
        "print(f'Accuracy on train set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMBXbqcqV39T",
        "outputId": "3ad448f0-6ee7-4945-d719-3568af678bb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_184/1239849378.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 54.305%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        features, targets = data\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for i, target in enumerate(targets):\n",
        "          one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n",
        "          correct += torch.all(torch.eq(targets[i], one_hot[i])).item()\n",
        "        total += targets.size(0)\n",
        "print(f'Accuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "B_U9mZRJiaRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skc9VGqlJUWX"
      },
      "outputs": [],
      "source": [
        "# Save the entire model (architecture + weights)\n",
        "torch.save(model, 'complete_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/MyDrive/Lab/Part 1/complete_model.pth')"
      ],
      "metadata": {
        "id": "DjU4ZKj_N3t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    count = 0\n",
        "    for data in test_loader:\n",
        "        features, targets = data\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        count += 32\n",
        "        print(\"count:\", count)\n",
        "\n",
        "        for i, target in enumerate(targets):\n",
        "          one_hot = torch.nn.functional.one_hot(torch.tensor(predicted), 11)\n",
        "          correct += torch.all(torch.eq(targets[i], one_hot[i])).item()\n",
        "\n",
        "          test_df.loc[count, 'Predicted Rating'] = int(predicted[i])\n",
        "        total += targets.size(0)\n",
        "print(f'Accuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "id": "3NCZVEHnKwDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Book Recomendations based on some Input Data"
      ],
      "metadata": {
        "id": "HG8PStWbBvA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = test_df.loc[(test_df['Location'] == \"colorado springs, colorado, usa\") & (test_df['Age'] == 52.0)].nlargest(5, 'Predicted Rating')\n",
        "print(\"Here are the top 5 five recommended books for user 198929 who is living in colorado springs, colorado, usa and their age is 52:\\n\")\n",
        "count = 1\n",
        "for i, book in books.iterrows():\n",
        "  print(count, \":\", book['Book-Title'], \"by\", book['Book-Author'])\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlewWpbqQ37d",
        "outputId": "42562014-c259-4285-e03e-45e74ff09eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 5 five recommended books for user 198929 who is living in colorado springs, colorado, usa and their age is 52:\n",
            "\n",
            "1 : Dance of the Flame by Elaine Barbieri\n",
            "2 : House by Tracy Kidder\n",
            "3 : The Saving Graces: A Novel by Patricia Gaffney\n",
            "4 : How Do Dinosaurs Learn to Read by Jane Yolen\n",
            "5 : Remote Control by Andy McNab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books = test_df.loc[(test_df['Location'] == \"ottawa, ontario, canada\") & (test_df['Age'] == 32.0)].nlargest(5, 'Predicted Rating')\n",
        "print(\"Here are the top 5 five books recommended for user 44839 who is living in ottawa, ontario, canada and their age is 32:\\n\")\n",
        "count = 1\n",
        "for i, book in books.iterrows():\n",
        "  print(count, \":\", book['Book-Title'], \"by\", book['Book-Author'])\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trMghlgkYCr2",
        "outputId": "c64a47c9-0e31-4ce6-d584-caf8c770aec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 5 five books recommended for user 44839 who is living in ottawa, ontario, canada and their age is 32:\n",
            "\n",
            "1 : Burning Bright: A Play in Story Form (Penguin Twentieth Century Classics) by John Steinbeck\n",
            "2 : The King of Torts by John Grisham\n",
            "3 : One Flew Over the Cuckoo's Nest by Ken Kesey\n",
            "4 : The Stand: Complete and Uncut by Stephen King\n",
            "5 : Childhood's End by Arthur C. Clarke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books = test_df.loc[(test_df['Location'] == \"fairbanks, alaska, usa\") & (test_df['Age'] == 30.0)].nlargest(5, 'Predicted Rating')\n",
        "print(\"Here are the top 5 five books recommended for user 98741 who is living in fairbanks, alaska, usa and their age is 30:\\n\")\n",
        "count = 1\n",
        "for i, book in books.iterrows():\n",
        "  print(count, \":\", book['Book-Title'], \"by\", book['Book-Author'])\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yesOcXfYZEA",
        "outputId": "39858338-83e4-47d7-f4eb-c7aeb7094952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 5 five books recommended for user 98741 who is living in fairbanks, alaska, usa and their age is 30:\n",
            "\n",
            "1 : The Charmer by Patrick Hamilton\n",
            "2 : America: The Vegetarian Table (Vegetarian Table) by Deborah Madison\n",
            "3 : Native American Songs and Poems: An Anthology (Dover Thrift Editions) by Brian Swann\n",
            "4 : The Diva Principle (Ay Insp - Hammond) by Michelle McKinney Hammond\n",
            "5 : Why Do Clocks Run Clockwise? by David Feldman\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}